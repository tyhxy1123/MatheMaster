% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy
% of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or
% send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\chapter{Anwendungen} %eigentlich ist das das dritte Kapitel
\section{Approximation}

\begin{theorem}[Trotter-Kato-Miyadera]\label{theoremTrotterKatoMiyadera}\enter
	Sei $(A_n)_{n\in\N}$ ein Folge von $m$-akkretiven Operatoren (vom uniformen Typ $\omega\in\R$, d.h. $\omega$ hängt nicht von $n$ ab) auf einem Banachraum $X$. Sei $(S_n)_{n\in\N}$ die zugehörige Folge von nichtlinearen Halbgruppen ($S_n$ ist Halbgruppe auf $D_n:=\overline{\dom(A_n)}$). Betrachte die folgenden Aussagen:
	\begin{enumerate}[label=(\roman*)]
		\item Für jede konvergente Folge $(u_{0,n})_{n\in\N}$ in $X$ mit $u_{0,n}\in D_n~\forall n\in\N$ und\\ $u_0:=\limn u_{0,n}$ existiert
		\begin{align*}
			\limn S_n(t) u_{0,n}=:S(t) u_0
		\end{align*}
		gleichmäßig für $t$ in kompakten Teilmengen in $\R_+$.
		\item Es existiert ein $\lambda_0>0$ mit $\lambda_0\cdot\omega<1$ so, dass für alle $f\in X$
		\begin{align*}
			\limn J_{\lambda_0}^{A_n} f=:J_{\lambda_0}f\qquad \Big(\mit J_{\lambda_0}^{A_n}=\big(I+\lambda_0\cdot A_n\big)^{-1}\Big)
		\end{align*}
		existiert.
		\item Für alle $\lambda>0$ mit $\lambda\cdot\omega<1$ und alle $f\in X$ existiert
		\begin{align*}
			\limn J_\lambda^{A_n} f=:J_\lambda f
		\end{align*}
		\item Für alle $\lambda>0$ mit $\lambda\cdot\omega<1$ und alle konvergenten Folgen $(f_n)_{n\in\N}$ in $X$ mit $f:=\limn f_n$ existiert
		\begin{align*}
			\limn J_\lambda^{A_n}f_n=:J_\lambda f
		\end{align*}
		\item Für jede konvergente Folge $(u_{0,n})_{n\in\N}$ in $X$ mit $u_{0,n}\in D_n~\forall n\in\N$ und\\ $u_0=\limn u_{0,n}$ und jede konvergente Folge $(f_n)_{n\in\N}$ in $L^1(0,T;X)$ mit $f=\limn f_n$ gilt:
		Sind $u,u_0\in C\big([0,1];X\big)$ die eindeutigen Integrallösungen von
		\begin{align*}
			\left\lbrace\begin{array}{r}
				\dot{u}+A_n u_n\ni f_n\\
				u_n(0)=u_{0,n}
			\end{array}\right.\qquad\text{und}\qquad
			\left\lbrace\begin{array}{r}
				\dot{u}+A u\ni f\\
				u(0)=u_{0}
			\end{array}\right.
		\end{align*}
		wobei $A\subseteq X\times X$ der Operator ist mit $J_\lambda^A=J_\lambda$ (wie in (iii) und (iv)), dann gilt
		\begin{align*}
			\limn\big\Vert u_n-u\big\Vert_{C\big([0,T];X\big)}=0
		\end{align*}
	\end{enumerate}
	Dann gilt: (i) $\Longleftarrow$ (ii) $\Longleftrightarrow$ (iii) $\Longleftrightarrow$ (iv) $\Longleftrightarrow$ (v)\\
	Falls $X$ ein Hilbertraum ist, dann gilt auch (i) $\Longleftrightarrow$ (ii).\nl
	Zu (iv) $\Longrightarrow$ (v): Wenn die äquivalenten Aussagen (ii),(iii),(iv) gelten, dann ist $J_\lambda$ Resolvente eines $m$-akkretiven Operators $A$ vom Typ $\omega$. Die von $A$ erzeugte Halbgruppe ist die Halbgruppe $S$ aus (i).
\end{theorem}

\begin{proof}
	Wir zeigen hier nur (i) $\Longleftarrow$ (ii) $\Longleftrightarrow$ (iii) $\Longleftrightarrow$ (iv).\nl
	\underline{Vorbetrachtung:}\\
	Auf dem Raum $c(\N,X)$ aller konvergenten Folgen in $X$(Banachraum  bzgl. Supremumsnorm $\Vert\cdot\Vert_\infty$) betrachten wir den Operator
	\begin{align*}
		\A=\Big\lbrace\big((u_n)_{n\in\N},(f_n)_{n\in\N}\big)\in c(\N,X)\times c(\N,X):\big(u_n,f_n)\in A_n~\forall n\in\N\Big\rbrace
	\end{align*}	 
	Weil die $A_n$ akkretiv vom Typ $\omega$ sind, gilt für alle $(u_n,f_n),(\hat{u}_n,\hat{f}_n)\in A_n$ und alle $\lambda>0$ mit $\lambda\cdot\omega<1$:
	\begin{align*}
		\Big\Vert u_n-\hat{u}_n+\lambda\cdot(f_n-\hat{f}_n)\Big\Vert_X
		&\geq(1-\lambda\cdot\omega)\cdot\big\Vert u_n-\hat{u}_n\big\Vert
	\end{align*}
	Also gilt (nehme Supremum auf beiden Seiten) für alle\\ $\big((u_n)_{n\in\N},(f_n)_{n\in\N}\big),\big((\hat{u}_n)_{n\in\N},(\hat{f}_n)_{n\in\N}\big)\in\A$ und alle $\lambda>0$ mit $\lambda\cdot\omega<1$
	\begin{align*}
		\Big\Vert(u_n)_{n\in\N}-(\hat{u}_n)_{n\in\N}+\lambda\cdot\big((f_n)_{n\in\N}-(\hat{f}_n)_{n\in\N}\big)\Big\Vert_\infty
		&\geq(1-\lambda\cdot\omega)\cdot\Big\Vert(u_n)_{n\in\N}-(\hat{u}_n)_{n\in\N}\Big\Vert_\infty
	\end{align*}
	Also ist $\A$ akkretiv vom Typ $\omega$.\nl
	%\underline{Es gelte nun Aussage (ii):}\\
	\underline{Zeige (ii)$\implies$(iv):}
	Sei $(f_n)_{n\in\N}\in c(\N,X),~f:=\limn f_n$. Dann gilt:
	\begin{align*}
		\Big\Vert J_{\lambda_0}^{A_n} f_n-J_{\lambda_0} f\Big\Vert
		&=\Big\Vert J_{\lambda_0}^{A_n} f_n\underbrace{-J_{\lambda_0}^{A_n} f+J_{\lambda_0}^{A_n} f}_{=0}-J_{\lambda_0} f\Big\Vert_X\\
		\overset{\text{DU}}&\leq
		\Big\Vert J_{\lambda_0}^{A_n} f_n-J_{\lambda_0}^{A_n} f\Big\Vert_X+\Big\Vert J_{\lambda_0}^{A_n} f-J_{\lambda_0} f\Big\Vert_X\\
		\overset{(\ast)}&\leq
		\frac{1}{1-\lambda_0\cdot\omega}\cdot\big\Vert f_n-f\big\Vert+\Big\Vert J_{\lambda_0}^{A_n} f-J_{\lambda_0}f\Big\Vert_X\stackrel{n\to\infty}{\longrightarrow} 0
	\end{align*}
	Bei $(\ast)$ wird verwendet, dass $J_{\lambda_0}^{A_n}$ Lipschitzstetig mit Lipschitzkonstante $\frac{1}{1-\lambda_0\cdot\omega}$ ist. 
	Folglich ist 
	\begin{align*}
		(u_n)_{n\in\N}:=\Big(J_{\lambda_0}^{A_n} f_n\Big)_{n\in\N}\in c(\N,X)
	\end{align*}
	Damit ist $(u_n)_{n\in\N}\in\dom(\A)$ und 
	\begin{align*}
		\big(I+\lambda_0\cdot\A\big)(u_n)_{n\in\N}\ni (f_n)_{n\in\N}
	\end{align*}
	(Es gilt
	\begin{align*}
		u_n+\lambda_0\cdot A_n u_n\ni f_n
		\quad\text{bzw.}\quad
		A_n u_n\ni\frac{f_n-u_n}{\lambda_0}		
		\quad\text{bzw.}\quad
		\left(u_n,\frac{f_n-u_n}{\lambda_0}\right)\in A_n\quad\forall n\in\N
	\end{align*}
	und somit $\left((u_n)_{n\in\N},\left(\frac{f_n-u_n}{\lambda_0}\right)_{n\in\N}\right)\in\A$.)\nl
	Wir haben gezeigt, dass $I+\lambda_0\cdot\A$ surjektiv ist. Weil $\A$ akkretiv vom Typ $\omega$ ist, ist damit  $A$ $m$-akkretiv vom Typ $\omega$ und damit ist $I+\lambda\cdot\A$ surjektiv (bijektiv) für alle $\lambda>0$ mit $\lambda\cdot\omega<1$.
	Daraus folgt Eigenschaft (iv).\nl
	\underline{Zeige (iv)$\implies$(iii)$\implies$(ii):} Trivial.\nl
	Nachrechnen: Die $J_\lambda$ sind von der Form $J_\lambda^A$ für einen $m$-akkretiven Operator vom Typ $\omega$.\nl
	\underline{Zeige (ii)$\implies$(i):}\\
	Es gelte nun eine der äquivalenten Aussagen (ii),(iii),(iv). Dann ist der Operator $\A$ $m$-akkretiv vom Typ $\omega$.
	Der Operator $\A$ erzeugt also eine Halbgruppe $\mathcal{S}$ auf dem Raum $c(\N,X)$.\\
	Die Exponentialformel zeigt:
	\begin{align*}
		\mathcal{S}(t)(u_{0,n})
		\overset{\text{Exp-Formel}}&=
		\lim\limits_{k\to\infty}\left(J_{\frac{t}{k}}^{\A}\right)^k(u_{0,n})_{n\in\N}\\
		&=\lim\limits_{k\to\infty}\left(\left(J_{\frac{t}{k}}^{A_n}\right)^k u_{0,n}\right)_{n\in\N}\\
		\overset{\text{Exp-Formel}}&=
		\left(S_n(t) u_{0,n}\right)\in  c(\N,X)
		\qquad\forall (u_{0,n})_{n\in\N}\in\overline{\dom(\A)}
	\end{align*}
	Daraus folgt (i). (Zeige dafür:
	\begin{align*}
		\overline{\dom(\A)}=\Big\lbrace(u_{0,n})_{n\in\N}\in c(\N,X)~\Big|~ u_{0,n}\in D_n\Big\rbrace~)
	\end{align*}
\end{proof}

\textbf{Erinnerung.}
Seien $A_n$ akkretiv vom Typ $\omega\in\R$. Dann gilt:
\begin{align*}
	\Big(\exists\lambda>0\mit\lambda\cdot\omega<1:\forall x\in X:
	J_\lambda^{A_n} x\longrightarrow J_\lambda^A x\Big)\implies\forall x\in X:S_n(t)x\longrightarrow S(t)x
\end{align*}
Die Konvergenz der $S_n$ ist hierbei gleichmäßig in $t$ (aus kompakten Teilmengen von $[0,\infty)$).

\section{Yosidaapproximation}
\begin{definition}
	Sei $A\subseteq X\times X$ $m$-akkretiv vom Typ $\omega\in\R$, $\lambda>0,\lambda\cdot\omega<1$.
	Dann heißt
	\begin{align*}
		A^\lambda:=\frac{1}{\lambda}\left(I-J_\lambda^A\right)
	\end{align*}
	\textbf{Yosidaapproximation} von $A$ ($J_\lambda^A:=(I-\lambda\cdot A)^{-1}$)
\end{definition}

\begin{theorem}[Eigenschaften der Yosidaapproximationen]\
	\begin{enumerate}[label=(\alph*)]
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1,\forall u\in X:\big(J_\lambda u,A^\lambda u\big)\in A
		\end{aligned}$
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1
		\end{aligned}$ ist $A^\lambda$ Lipschitzstetig mit Lipschitzkonstante $\frac{2-\lambda\cdot\omega}{\lambda\cdot(1-\lambda\cdot\omega)}$.
		\item $\forall\lambda>0\mit\lambda\cdot\omega<1$ ist $A^\lambda$ $m$-akkretiv vom Typ $\frac{\omega}{1-\lambda\cdot\omega}$.
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1,\forall u\in\dom(A):			
		\end{aligned}$
		\begin{align*}
			(1-\lambda\cdot\omega)\cdot\Vert A^\lambda u\Vert_X\leq\Vert A u\Vert:=\inf\big\lbrace\Vert f\Vert_X:(u,f)\in A\big\rbrace
		\end{align*}
		\item $\begin{aligned}
			\forall\lambda,\mu>0\mit(\mu+\lambda)\cdot\omega<1:
			A^{\lambda+\mu}=\big(A^\lambda\big)^\mu
		\end{aligned}$
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1,\forall f\in X:
			\lim\limits_{\mu\to0^+}J_\lambda^{A^\mu}f=J_\lambda^A f
		\end{aligned}$
	\end{enumerate}
\end{theorem}

\begin{proof}
	\underline{Zeige (a):}
	\begin{align*}
		A J_\lambda u
		&=\frac{-I+I+\lambda\cdot A}{\lambda}J_\lambda u
		\ni\frac{1}{\lambda}\cdot(I-J_\lambda)u
		=A^\lambda u
	\end{align*}
	Hierbei geht ein, dass $u\in(I+\lambda\cdot A)J_\lambda u$ gilt)
	Folglich ist $\big(J_\lambda u,A^\lambda u\big)\in A$.\nl
	\underline{Zeige (b):}\\
	$J_\lambda$ ist Lipschitzstetig mit Konstante $\frac{1}{1-\lambda\cdot\omega}$.\nl
	\underline{Zeige (c):}
	Allgemein gilt:\\
	Ist $S$ Lipschitzstetig mit Lipschitzkonstante $L$, dann ist $L\cdot I-S$ $m$-akkretiv (vom Typ 0), siehe Beispiele von akkretiven Operatoren). ($m$-Akkretivität ist Übung!). Also ist
	\begin{align*}
		\frac{1}{\lambda}\cdot\left(\frac{1}{1-\lambda\cdot\omega}-J_\lambda\right)
	\end{align*}
	$m$-akkretiv, d.h. $\frac{\omega}{1-\lambda\cdot\omega}+A^\lambda$ ist $m$-akkretiv, d.h. $A^\lambda$ ist $m$-akkretiv vom Typ $\frac{w}{1-\lambda\cdot\omega}$.\nl
	\underline{Zeige (e):}\\
	Seien $\lambda,\mu>0$ mit $(\lambda+\mu)\cdot\omega<1$.
	Es gilt
	\begin{align*}
		A^\mu u=f
		&\Longleftrightarrow \frac{I-J_\mu^A}{\mu} u=f\\
		&\Longleftrightarrow J_\mu^A u=u-\mu\cdot f\\
		&\Longleftrightarrow(u-\mu\cdot f)+\mu\cdot A(u-\mu\cdot f)\ni u\\
		&\Longleftrightarrow A(u-\mu\cdot f)\ni f
	\end{align*}
	Diese Äquivalenz gilt auch für $A^\lambda$ anstelle von $A$, d.h.
	\begin{align*}
		\big(A^\lambda)^\mu u=f
		&\Longleftrightarrow A^\lambda(u-\mu f)\ni u\\
		\overset{\text{Äquivalenz für }A}&{\Longleftrightarrow}
		A\big(u-(\mu+\lambda)\cdot f\big)\ni f\\
		\overset{\text{Äquivalenz für }A}&{\Longleftrightarrow}
		A^{\lambda+\mu} u=f
	\end{align*}
	\underline{Zeige (d):}\\
	Sei $u\in\dom(A),\lambda>0$ mit $\lambda\cdot\omega<1$.
	Sei $f\in A u$.
	Nach (a) gilt $A^\lambda u\in A J_\lambda u$.
	Weil $A$ akkretiv vom Typ $\omega$ ist, folgt daraus 
	\begin{align*}
		\hspace{5pt}\big[u-J_\lambda u,f-A^\lambda u\big]+\omega\cdot\big\Vert u-J_\lambda u\big\Vert&\geq0\\
		\implies
		\big[u-J_\lambda u,f-A^\lambda u\big]+\lambda\cdot\omega\cdot\frac{\big\Vert u-J_\lambda u\big\Vert_X}{\lambda}&\geq0\\
		\implies
		0&\leq\lambda\cdot\omega\cdot\big\Vert A^\lambda u\big\Vert_X+\big[A^\lambda u,f-A^\lambda u\big]\\
		&\leq\lambda\cdot\big\Vert A^\lambda u\big\Vert_X+\big[A^\lambda u,f\big]+\big[A^\lambda u,-A^\lambda u\big]\\
		&\leq\lambda\cdot\omega\cdot\big\Vert A^\lambda u\big\Vert+\Vert f\Vert_X-\big\Vert A^\lambda\big\Vert_X\\
		\implies\big\Vert A^\lambda u\big\Vert_X
		&\leq\frac{1}{1-\lambda\cdot\omega}\cdot\Vert f\Vert_X
		\qquad\forall f\in Au
	\end{align*}
	\underline{Zeige (f):}\\
	Aus (e) folgt
	\begin{align*}
		A^{\mu+\lambda}
		\overset{\text{(e)}}&=
		\left(A^\mu\right)^\lambda
		\overset{\text{Def}}=
		\frac{I-J_\lambda^{A^\mu}}{\lambda}
	\end{align*}
	Somit gilt für alle $f\in X$:
	\begin{align*}
		J_\lambda^{A^\mu} f
		&= f-\lambda\cdot A^{\mu+\lambda} f
		=f-\lambda\cdot\left(\frac{f-J_{\mu+\lambda}^A}{\mu+\lambda}\right)
		=\frac{\mu}{\mu+\lambda}\cdot f+\frac{\lambda}{\mu+\lambda}\cdot J_{\mu+\lambda}^A f
		\overset{\mu\to0^+}{\longrightarrow}J_\lambda^A f
	\end{align*}
	Beim Grenzübergang wird die Stetigkeit der Resolvente $A$ verwendet, in Abhängigkeit von $\lambda$.
\end{proof}

\begin{bemerkung}
	Aus der Eigenschaft (f) der Yosidaapproximation und aus dem Theorem von Trotter-Kato-Miyadera \ref{theoremTrotterKatoMiyadera} folgt, dass die von $A^mu$ erzeugten Halbgruppen $S_\mu$ 
	(hier genügt der Satz von Picard-Lindelöf!)
	stark gegen die von $A$ erzeugte Halbgruppe $S$ konvergieren
	(für $\mu\to0^+$).
	\begin{align*}
		S_\mu(t)u_0\overset{\mu\to0^+}{\longrightarrow} S(t)u_0
		\qquad\forall u_0\in\overline{\dom(A)},\forall t\geq0
	\end{align*}
\end{bemerkung}

\begin{definition}
	Sei $H$ ein Hilbertraum und sei $\E:H\to\R\cup\lbrace+\infty\rbrace$ unterhalbstetig, $\not\equiv+\infty$, semikonvex von Typ $\omega\in\R$, d.h.
	\begin{align*}
		u\mapsto\E(u)+\frac{\omega}{2}\cdot\Vert u\Vert^2_H\text{ ist konvex.}
	\end{align*}
	Dann heißt (für $\lambda>0$ mit $\lambda\cdot\omega<1$
	\begin{align*}
		\E^\lambda:H\to\R,\qquad
		\E^\lambda(u):=\inf\limits_{v\in H}\left(\E(v)+\frac{1}{2\cdot\lambda}\cdot\Vert u-v\Vert^2_H\right)
	\end{align*}
	\textbf{Moreau-Yosida-Approximation} von $\E$.
\end{definition}

\begin{theorem}[Eigenschaften der Moreau-Yosida-Approximationen]\label{theoremEigenschaftenDerMoreuaYosiaApproximation}\
	\begin{enumerate}[label=(\alph*)]
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1,\forall u\in H:
		\end{aligned}$
		\begin{align*}
			\E^\lambda(u)
			=\E\left(J_\lambda u\right)+\frac{1}{2\cdot\lambda}\cdot\big\Vert u-J_\lambda^{\partial\E} u\big\Vert_H^2
			=\E\big(J_\lambda u\big)+\frac{\lambda}{2}\cdot\big\Vert(\partial\E)^\lambda u\big\Vert_H^2
		\end{align*}				
		 wobei $\partial\E$ der Subgradient von $\E$, $(\partial\E)^\lambda$ die Yosidaapproximation von $\partial\E$ und $J_\lambda=\big(I+\lambda\cdot\partial\E\big)^{-1}$ die Resolvente von $\partial\E$ ist.
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1
		\end{aligned}$ ist $\E^\lambda$ stetig differenzierbar und semikonvex vom Typ $\frac{\omega}{1-\lambda\cdot\omega}$.
		\item $\begin{aligned}
			\forall u\in H
		\end{aligned}$ ist die Funktion $\lambda\mapsto\E^\lambda(u)$ monoton fallend und 
		\begin{align*}
			\sup\limits_{\lambda>0}\E^\lambda(u)=\lim\limits_{\lambda\to0^+}\E^\lambda(u)\overset{!}{=}\E(u)
		\end{align*}
		\item $\begin{aligned}
			\forall u\in H
		\end{aligned}$ ist die Funktion $\lambda\mapsto\lambda\cdot\E^\lambda(u)$ konkav und stetig differenzierbar und 
		\begin{align*}
			\frac{\d}{\d\lambda}\big(\lambda\cdot\E^\lambda(u)\big)=\E\big(J_\lambda^{\partial\E} u\big)
		\end{align*}
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1:\partial\big(\E^\lambda\big)=(\partial\E)^\lambda
		\end{aligned}$\\
		Auf der linken Seite steht der Subgradient (=Frechétableitung) von $\E^\lambda$ und auf der rechten Seite die Yosidaableitung von $\partial\E$.
		\item $\begin{aligned}
			\forall f\in H,\forall\lambda>0\mit\lambda\cdot\omega<1:
			\lim\limits_{\mu\to0^+}J_\lambda^{\partial\E^\mu}f=J_\lambda^{\partial\E} f
		\end{aligned}$
	\end{enumerate}
\end{theorem}

\begin{proof}
	\underline{Zeige (a):}\\
	$J_\lambda u$ ist der globale Minimierer der Funktion 
	\begin{align*}
		v\mapsto\E(v)+\frac{1}{2\cdot\lambda}\cdot\Vert u-v\Vert^2_H
	\end{align*}
	(siehe Beweis, dass $\partial\E$ $m$-akkretiv vom Typ $\omega$ ist, also die Surjektivität)\nl
	\underline{Zeige (b):} Ohne Beweis.\nl
	\underline{Zeige (c):} Es gilt:
	\begin{align*}
		\E^\lambda(u)
		&=\inf\limits{v\in H}\left(\E(v)+\frac{1}{2\cdot\lambda}\cdot\Vert u-v\Vert^2\right)\\
		\overset{\text{wähle }v=u}&{\leq}
		\E(u)\qquad\forall\lambda>0\mit\lambda\cdot\omega<1,\forall u\in H
	\end{align*}
	Außerem ist $\forall v\in H$ die Funktion $\lambda\mapsto\E(u)+\frac{1}{2\cdot\lambda}\cdot\Vert u-v\Vert_H^2$ monoton fallend und damit ist 
	$\E^\lambda(u)=\inf\limits{v\in H}\left(\E(v)+\frac{1}{2\cdot\lambda}\cdot\Vert u-v\Vert^2\right)$ monoton fallend.
	Damit ist
	\begin{align*}
		\sup\limits_{\lambda>0}\E^\lambda(u)
		&=\lim\limits_{\lambda\to0^+}\E^\lambda(u)\leq\E(u)
	\end{align*}
	Die Abschätzung $\ldots\geq\E(u)$ ist Übung.\nl
	\underline{Zeige (d):}\\
	Für alle $v\in H$ ist die Funktion $\lambda\mapsto\lambda\cdot\E(u)+\frac{1}{2}\cdot\Vert v-u\Vert^2_H$ konkav, 
	und damit ist $\lambda\mapsto\lambda\cdot\E^\lambda(u)=\inf\limits_{v\in H}\left(\E(v)+\frac{1}{2\cdot\lambda}\cdot\Vert u-v\Vert^2\right)$
	konkav (punktweise Infimum konkaver Funktionen ist konkav).
	Damit ist $\lambda\mapsto\lambda\cdot\E^\lambda(u)$ insbesondere stetig.
	Seien $\lambda_1,\lambda_2>0$ mit $\lambda_1\cdot\omega,\lambda_2\cdot\omega<1$ und sei $u\in H$.
	Dann ist
	\begin{align*}
		&\lambda_1\cdot\E^{\lambda_1}(u)-\lambda_2\cdot\E^{\lambda_2}(u)\\
		\overset{\text{(a)}}&=
		\lambda_1\cdot\inf\limits_{v\in H}\left(\E(v)+\frac{1}{2\cdot\lambda_1}\cdot\Vert u-v\Vert^2_H\right)
		-\left(\lambda_2\cdot\E\big(J_{\lambda_2} u\big)+\frac{1}{2\cdot\lambda_2}\cdot\big\Vert u-J_{\lambda_2} u\big\Vert_H^2\right)\\
		\overset{\text{setze }v=J_{\lambda_2}u}&\leq
		\lambda_1\cdot\E\big(J_{\lambda_2} u\big)+\frac{1}{2}\cdot\big\Vert u-J_{\lambda_2} u\big\Vert^2_H
		-\lambda_2\cdot\E\big(J_{\lambda_2} u\big)-\frac{1}{2}\cdot\big\Vert u-J_{\lambda_2} u\big\Vert^2_H\\
		&=\big(\lambda_1-\lambda_2\big)\cdot\E\big(J_{\lambda_2}u\big)
	\end{align*}
	Vertausche Rollen von $\lambda_1$ und $\lambda_2$:
	\begin{align*}
		\big(\lambda_1-\lambda_2\big)\cdot\E\big(J_{\lambda_1} u\big)
		&\leq \lambda_1\cdot\E^{\lambda_1}(u)-\lambda_2\cdot\E^{\lambda_2}(u)\\
		&\leq\big(\lambda_1-\lambda_2\big)\cdot\E\big(J_{\lambda_2}u\big)
	\end{align*}
	Da $\lambda\mapsto\E\big(J_{\lambda} u\big)$ stetig ist, folgt die Behauptung.\nl
	\underline{Zeige (e):} Ohne Beweis.\nl
	\underline{Zeige (f):}\\
	Folgt aus (e) und den Eigenschaften der Yosidaapproximationen.
\end{proof}

\begin{definition}
	Sei $H$ ein Hilbertraum und seien $\E,\E_n:H\to\R\cup\lbrace+\infty\rbrace$ Funktionen.
	Die Folge $(\E_n)_{n\in\N}$ heißt \textbf{Mosco-konvergent} gegen $\E:\gdw$
	\begin{enumerate}[label=(\roman*)]
		\item für jede schwach konvergente Folge $(u_n)_{n\in\N}$ in $H$ mit $u=\weaklim\limits_{n\to\infty} u_n$ gilt
		\begin{align*}
			\E(u)\leq\liminf\limits_{n\to\infty}\E_n(u_n)
		\end{align*}
		\item Für jedes $u\in H$ gibt es eine "recovery sequence" $(u_n)_{n\in\N}$ in $H$ mit $\limn u_n=u$ 
		(starke (übliche) Konvergenz!) und 
		\begin{align*}
			\E(u)\geq\limsup\limits_{n\to\infty}\E_n(u_n)\\
			\Big(\overset{\text{wg. (i)}}{\Longleftrightarrow}
			\E(u)=\limn\E_n(u_n)\Big)
		\end{align*}
	\end{enumerate}
\end{definition}

\begin{bemerkung}
	Die bekannte \textit{$\Gamma$-Konvergenz} unterscheidet sich von der Moscow-\\Konvergenz nur dadurch, dass die (i) starke Konvergenz gefordert wird.
	\begin{align*}
		\E_n\overset{\text{Moscow}}{\longrightarrow}\E\implies\E_n\overset{\Gamma}{\longrightarrow}\E
	\end{align*}
\end{bemerkung}

\begin{lemma}
	Seien $\E,\E_n:H\to\R\cup\lbrace+\infty\rbrace$ unterhalbstetig, $\not\equiv0$, konvexe so, dass 
	\begin{align*}
		\E_n\overset{\text{Moscow}}{\longrightarrow}\E.
	\end{align*}
	Dann gibt es Konstanten $c\in\R,r>0$ so, dass 
	\begin{align*}
		\forall n\in\N,\forall u\in H:
		\E_n(u)\geq c-r\cdot\Vert u\Vert_H
	\end{align*}
\end{lemma}

\begin{proof}
	Übung.
\end{proof}

\begin{theorem}
	Seien $\E_n:H\to\R\cup\lbrace+\infty\rbrace$ unterhalbstetig und konvex.
	Dann gilt:
	\begin{enumerate}[label=(\alph*)]
		\item Wenn $(\E_n)_{n\in\N}$ monoton wachsend und konvergent ist, dann ist $(\E_n)_{n\in\N}$ Mosco-konvergent mit
		\begin{align*}
			\E_n\overset{\text{Mosco}}{\longrightarrow}\sup\limits_{n\in\N}\E_n
		\end{align*}
		\item Wenn $(\E_n)_{n\in\N}$ monoton fallend und von unten durch eine unterhalbstetige Funktion beschränkt ist,
		dann ist $(\E_n)_{n\in\N}$ Mosco-konvergent mit
		\begin{align*}
			\E_n\overset{\text{Mosco}}{\longrightarrow}\overline{\inf\limits_{n\in\N}\E_n}
		\end{align*}
		Hierbei meint die Überstreichung die \textbf{unterhalbtstetige Hülle}, d.h. die größte unterhalbstetige Funktion, die kleiner als dieses Infimum ist.
	\end{enumerate}
\end{theorem}

\begin{proof}
	\underline{Zeige (a):}\\
	Sei $(u_n)_{n\in\N}$ schwach konvergent in $H$, $u:=\weaklim\limits_{n\to\infty} u_n$.\\
	Für $n\geq m~(m,n\in\N)$ gilt
	\begin{align*}
		\E_m(u_n)
		&\leq\E_n(u_n)
	\end{align*}
	Es gilt:
	\begin{align*}
		\E_n\text{ unterhalbstetig (Norm)}
		&\Longleftrightarrow
		\big\lbrace\E_n\leq c\big\rbrace\text{ abgeschlossen in }H &\forall c\in \R\\
		\overset{\E_m\text{ konvex+Hahn-B.}}&{\Longleftrightarrow}
		\big\lbrace\E_m\leq c\big\rbrace\text{ schwach abgeschlossen in }H &\forall c\in\R\\
		&\Longleftrightarrow\E_m\text{ unterhalbstetig bzgl. schwacher Topologie}
	\end{align*}
	Erinnerung: schwach abgeschlossen bedeutet abgeschlossen in der schwachen Topologie.
	Also gilt:
	\begin{align*}
		\E_m(u)
		&\leq\liminf\limits_{n\to\infty}\E_m(u_n)
		\leq\liminf\limits_{n\to\infty}\E_n(u_n)
		\qquad\forall m\\ %\leq n\\
		\implies
		\E(u)&:=\sup\limits_{m\in\N}\E_m(u)
		\leq\liminf\limits_{n\to\infty}\E_n(u_n)
	\end{align*}
	Außerdem sei $u\in H$.
	Setze $u_n:=u$.
	Dann gilt:
	\begin{align*}
		\sup\limits_{m}\E_m(u)=\E(u)=\limn\E_n(u_n)
	\end{align*}

	\underline{Zeige (b):}\\
	Sei $\E_n)_{n\in\N}$ monoton fallend, $\E_n\leq\mathcal{F}$, wobei $\mathcal{F}:H\to\R\cup\lbrace+\infty\rbrace$ unterhalbstetig.
	Sei $\E:=\overline{\inf\limits_{n\in\N}\E_n}(\geq\mathcal{F})$.
	Sei $(u_n)_{n\in\N}$ schwach konvergent in $H$, $u:=\weaklim\limits_{n\to\infty} u_n$.
	\begin{align*}
		\implies\E(u)\overset{\E\text{ konvex}}{\leq}\liminf\limits_{n\to\infty}\E(u_n)\leq\liminf\limits_{n\to\infty}\E_n(u_n)
	\end{align*}
	Außerdem: sei $u\in H$.
	Sei $\E^0(u):=\inf\limits_{n\in\N}\E_n(u)$ (so, dass $\E=\overline{\E^0}$).\\
	Dann existiert eine Folge $(v_n)_{n\in\N}$ in $H$ mit
	\begin{align*}
		\E(u)
		&=\limn\E^0(v_n)
		\qquad\text{und}\qquad
		\limn v_n=u
	\end{align*}
	(Der Epigraph von $\E$ ist der Abschluss in $H\times\R$ des Epigraphen von $\E^0$!)\\
	Nach Definition von $\E^0$ existiert für jedes $n\in\N$ ein $m_n\in\N$ so, dass
	\begin{align*}
		\E_{m_n}(v_n)\leq\E^0(v_n)+\frac{1}{n}
	\end{align*}
	O.B.d.A. (weil $(\E_m)_{m\in\N}$ monoton fallend ist) ist $(m_n)_{n\in\N}$ streng monoton wachsend.
	Setze nun $u_m:=v_1$ für $m\leq m_1$ und $u_m:=v_n$ für $m_{n-1}\leq m\leq m_n$.
\end{proof}

\begin{korollar}
	Sei $\E:H\to\R\cup\lbrace+\infty\rbrace$ unterhalbstetig,$\not\equiv\infty$ und semikonvex vom Typ $\omega\in\R$.
	Dann gilt:
	\begin{align*}
		\E^\lambda+\frac{\omega}{2\cdot(1-\lambda\cdot\omega)}\cdot\Vert\cdot\Vert_H^2
		\stackrelnew{\lambda\to0^+}{\text{Mosco}}{\longrightarrow}
		\E+\frac{\omega}{2}\cdot\Vert\cdot\Vert_H^2
	\end{align*}
\end{korollar}

\begin{proof}
	$\E^\lambda$ ist monoton wachsend 
	(siehe Eigenschaften der \\Moreau-Yoshida-Approximation)
\end{proof}

\begin{theorem}[ATTOUCH]\label{theoremATTOUCH}\enter
	Seien $\E_n,\E:H\to\R\cup\lbrace+\infty\rbrace$ unterhalbstetig, $\not\equiv+\infty$ und semikonvex vom Typ $\omega\in\R$
	auf einem Hilbertraum $H$.
	Seien $S_n$ und $S$ die von Subgradienten $\partial\E_n$ und $\partial\E$ erzeugten Halbgruppen.
	Dann sind folgende Aussagen äquivalent:
	\begin{enumerate}[label=(\roman*)]
		\item Für jede konvergente Folge $(u_n^0)_{n\in\N}$ (0 ist Anfangswert) in $H$ mit $u_n^0\in\overline{\dom(\partial\E_n)}$ und 
		mit $u^0:=\limn u_n^0$ gilt
		\begin{align*}
			u_0\in\overline{\dom(\partial\E)}
			\qquad\text{ und }\qquad
			\limn S_n(t)u_n^0=S(t) u^0
			\text{ lokal glm. in }t\in\R_{\geq0}
		\end{align*}
		und es gilt die Normalisierung
		\begin{align}\label{eqAttouchAN}\tag{N}
			\exists\big(\hat{u}_n,\hat{f}_n\big)\in\partial\E,\exists\big(\hat{u},\hat{f}\big)\in\partial\E:
			\limn\big(\hat{u}_n\hat{f}_n\big)=\big(\hat{u},\hat{f}\big)
			%\text{ in }H\times H
			\text{ und }\limn \E_n\big(\hat{u}_n\big)=\E\big(\hat{u}\big)
		\end{align}
		\item $\begin{aligned}
			\exists\lambda>0\mit\lambda\cdot\omega<1:\forall f\in H:
			\limn J_\lambda^{\partial\E_n} f=J_\lambda^{\partial\E} f\text{ in }H
			\text{ und }\eqref{eqAttouchAN}
		\end{aligned}$
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1,\forall f\in H:
			\limn J_\lambda^{\partial\E_n}f=J_\lambda^{\partial\E} f\text{ in }H
			\text{ und }\eqref{eqAttouchAN}
		\end{aligned}$
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1,\forall f\in H:
			\weaklim\limits_{n\to\infty} J_\lambda^{\partial\E_n} f=J_\lambda^{\partial\E}f
			\text{ und }\eqref{eqAttouchAN}
		\end{aligned}$
		\item $\begin{aligned}
			\forall\lambda>0\mit\lambda\cdot\omega<1,\forall u\in H:
			\lim\E_n^\lambda(u)=\E^\lambda(u)
		\end{aligned}$
		\item $\begin{aligned}
			\E_n+\frac{\omega}{2}\cdot\Vert\cdot\Vert^2
			\overset{\text{Mosco}}{\longrightarrow}
			\E+\frac{\omega}{2}\cdot\Vert\cdot\Vert^2
		\end{aligned}$
	\end{enumerate}
\end{theorem}

% Das Theorem existiert in der Form zum aktuellen Zeitpunkt nirgends in der Literatur. 
% Höchstens einzelne Äquivalenzen lassen sich finden.

\begin{proof}
	(i) $\gdw$ (ii) $\gdw$ (iii) folgt aus Trotter-Kato-Miyadera \ref{theoremTrotterKatoMiyadera}.\nl
	(iii) $\implies$ (iv) ist klar, da starke Konvergenz in jedem Banachraum schwache Konvergenz impliziert.\nl
	\underline{Zeige (vi) $\implies$ (iii)/(ii):}\\
	Sei $\lambda>0\mit\lambda\cdot\omega<1$.
	Sei $f\in H$.
	Aus dem Lemma oben %TODO add reference
	folgt die Existenz von $c,r>0$ so, dass $\forall u\in H,\forall n\in\N$:
	\begin{align*}
		\E_n(u)+\frac{\omega}{2}\cdot\Vert u\Vert^2
		&\geq -c-r\cdot\Vert u\Vert
	\end{align*}
	Sei $v\in H$.
	Wähle eine "recovery sequence" $(v_n)_{n\in\N}$ in $H$ mit $\limn\Vert v_n-v\Vert_H=0$
	und
	\begin{align*}
		\limn\E_n(v_n)+\frac{\omega}{2}\cdot\Vert v_n\Vert^2_H
		=\E(v)+\frac{\omega}{2}\cdot\Vert v\Vert^2_H
	\end{align*}
	Dann gilt (bei $(\ast)$ wird benutzt, dass $J_\lambda^{\partial\E_n}$ globaler Minimierer ist):
	\begin{align*}
		&\overbrace{\E_n(v_n)}^{\longrightarrow\E(v)}+\overbrace{\frac{1}{2\cdot\lambda}\cdot\Vert v_n-f\Vert_H^2}^{\longrightarrow\frac{1}{2\cdot\lambda}\cdot\Vert v-f\Vert^2}\\
		\overset{(\ast)}&\geq
		\E_n\Big(J_\lambda^{\partial\E_n} f\Big)+\frac{1}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\\
		&=\E_n\Big(J_\lambda^{\partial\E_n} f\Big)+\frac{\omega}{2}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2
		+\frac{1-\lambda\cdot\omega}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert^2_H\\
		\overset{\text{CS}}&\geq
		\E_n\Big(J_\lambda^{\partial\E_n}f\Big)+\frac{\omega}{2}\cdot\Big\Vert j_\lambda^{\partial\E_n} f\Big\Vert_H^2
		-|\omega|\cdot\Big\Vert J_\lambda^{\partial\E_n} f\Big\Vert_H\cdot\Vert f\Vert+\frac{\omega}{2}\cdot\Vert f\Vert_H^2\\
		&~~+\frac{1-\lambda\cdot\omega}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\\
		&\geq-c-r\cdot\Big\Vert J_\lambda^{\partial\E_n} f\Big\Vert_H
		-|\omega|\cdot\Big\Vert J_\lambda^{\partial\E_n} f\Big\Vert_H\cdot\Vert f\Vert+\frac{\omega}{2}\cdot\Vert f\Vert_H^2+\frac{1-\lambda\cdot\omega}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2
	\end{align*}
	Es folgt also:
	\begin{enumerate}
		\item Die Folge $\big(J_\lambda^{\partial\E_n} f\big)_{n\in\N}$ ist beschränkt.
		\item Die Folge $\Big(\E_n\big(J_\lambda^{\partial\E_n} f\big)\Big)_{n\in\N}$ ist beschränkt.
	\end{enumerate}
	Nach Auswahl einer Teilfolge von 2. (wieder mit $(\E_n)_{n\in\N}$ bezeichnet) gilt:\\
	$\big(J_\lambda^{\partial\E_n} f\big)_{n\in\N}$ ist schwach konvergent.
	Setze $u:=\weaklim\limits_{n\to\infty} J_\lambda^{\partial\E_n} f$.\\
	Wir zeigen: $u=J_\lambda^{\partial\E} f$.\\
	Sei noch einmal $v\in H$ und $(v_n)_{n\in\N}$ eine "recovery sequence" für $v$
	($v_n\overset{}{\longrightarrow} v$ und $\E_n(v_n)\overset{}{\longrightarrow}\E(v)$).
	Dann gilt:
	\begin{align*}
		\E(u)+\frac{1}{2\cdot\lambda}\cdot\Vert u-f\Vert_H^2
		\overset{\text{(i) von Mosco-Konv}}&\leq 
		\liminf\limits_{n\to\infty}\left(\E_n\Big(J_\lambda^{\partial\E_n} f\Big)+\frac{1}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\right)\\
		&\leq\limsup\limits_{n\to\infty}\left(\E_n\Big(J_\lambda^{\partial\E_n} f\Big)+\frac{1}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\right)\\
		&\leq\limsup\limits_{n\to\infty}\left(\E_n(v_n)+\frac{1}{2\cdot\lambda}\cdot\Vert v_n-f\Vert_H^2\right)\\
		&=\E(v)+\frac{1}{2 \cdot\lambda}\cdot\Vert v-f\Vert_H^2
	\end{align*}
	Da diese Abschätzung für alle $v\in H$ gilt, ist $u$ globaler Minimierer von 
	$v\mapsto\E(v)+\frac{1}{2}\cdot\Vert v-f\Vert_H^2$, d.h. $u=J_\lambda^{\partial\E} f$.
	Setzt man außerdem $v=u=J_\lambda^{\partial\E_n} f$ in die Abschätzung ein, dann folgt
	\begin{align}\label{eqProofAttouchStern}\tag{$\ast$}
		&\limn\left(\E_n\Big(J_\lambda^{\partial\E_n}f\Big)+\frac{1}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\right)
		=\E\Big(J_\lambda^{\partial\E}f\Big)+\frac{1}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E} f-f\Big\Vert_H^2\\\nonumber
		&\implies\limsup\limits_{n\to\infty}\frac{1-\lambda\cdot\omega}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\\\nonumber
		&\leq\limsup\limits_{n\to\infty}\left(\E_n\Big(J_\lambda^{\partial\E_n} f\Big)+\frac{1-\lambda\cdot\omega}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\right)\\\nonumber
		&~~~-\liminf\limits_{n\to\infty}\left(\E_n\Big(J_\lambda^{\partial\E_n} f\Big)+\frac{\omega}{2}\cdot\Big\Vert J_\lambda^{\partial\E_n} f-f\Big\Vert_H^2\right)\\\nonumber
		%+\liminf\limits_{n\to\infty}\Big\Vert J_\lambda^{\partial\E_n} f\Big\Vert_H^2\\ %wurde an der Tafel gelöscht
		\overset{(\ast)}&\leq 
		\E\Big(J_\lambda^{\partial\E} f\Big)+\frac{1}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E} f-f\Big\Vert_H^2
		-\E\Big(J_\lambda^{\partial\E} f\Big)-\frac{\omega}{2}\cdot\Big\Vert J_\lambda^{\partial\E} f\Big\Vert_H^2\\\nonumber
		&=\frac{1-\lambda\cdot\omega}{2\cdot\lambda}\cdot\Big\Vert J_\lambda^{\partial\E} f-f\Big\Vert_H^2	
	\end{align}
	Bei $(\ast)$ geht erneut Eigenschaft (i) der Mosco-Konvergenz ein.
	\begin{lemma}
		Aus $v_n\overset{n\to\infty}{\longrightarrow} v$ schwach in $H$ und $\limsup\limits_{n\to\infty}\Vert v_n\Vert\leq\Vert v\Vert$ folgt
		\begin{align*}
			\big\Vert v_n-v\big\Vert_H\overset{n\to\infty}{\longrightarrow}0.
		\end{align*}
	\end{lemma}
	
	\begin{proof}
		\begin{align*}
			\limsup\limits_{n\to\infty}\big\Vert v_n-v\big\Vert^2
			&=\limsup\limits_{n\to\infty}\Big(\Vert v_n\Vert^2-2\cdot\Re\big(\langle v_n,v\rangle\big)+\Vert v\Vert_H^2\Big)\\
			&\leq \Vert v\Vert^2-2\cdot\Vert v\Vert^2+\Vert v\Vert^2\\
			&=0
		\end{align*}
	\end{proof}
	
	Mit dem Lemma erhalten wir
	\begin{align*}
		\limn\Big\Vert J_\lambda^{\partial\E_n}f-J_\lambda f\Big\Vert_H^2=0
	\end{align*}
	
	Aus der Normkonvergenz $\big(J_\lambda^{\partial\E_n}f\big)$ gegen $J_\lambda^{\partial\E} f$ und (*) %TODO
	folgt
	\begin{align*}
		\limn E_n\Big(J_\lambda^{\partial\E_n}f\Big)=\E\big(J_\lambda^{\partial\E}f\Big)
	\end{align*}
	Jede Folge der Form $\left(\left(J_\lambda^{\partial\E_n} f,\frac{I-J_\lambda^{\partial\E_n}}{\lambda}\cdot f\right)\right)$ 
	($f\in H$) ist gut für die Normalisierungsbedingung \eqref{eqAttouchAN}.\nl
	Der Beweis der Rückrichtung entfällt.
\end{proof}

\begin{lemma}
	Sei $I\subseteq\R$ Intervall und seien $f_n,f:I\to\R$ stetig differenzierbare, konvexe Funktionen.
	Falls $f_n\overset{n\to\infty}{\longrightarrow} f$ punktweise überall,
	dann $f_n'\overset{n\to\infty}{\longrightarrow} f'$ lokal gleichmäßig.
\end{lemma}

\begin{proof}
	Übung.
\end{proof}

