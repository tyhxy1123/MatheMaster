% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy
% of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or
% send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\chapter{Zufällige Felder zweiter Ordnung}
\section{Korrelationsfunktion}

\begin{erinnerungnr}\label{erinnerung3.1.1}
	Ist $Z$ ein Feld zweiter Ordnung, so heißt
	\begin{align*}
		C(x,y)
		&:=\E\eckigeKlammern{Z(x)\mal\overline{Z(y)}} \qquad\forall x,y\in T
	\end{align*}
	Korrelationsfunktion von $Z$. 
	Die Kovarianzfunktion ist durch 
	\index{Korrelationsfunktion}
	\index{Kovarianzfunktion}
	\begin{align*}
		\sigma(x,y)&:=\E\eckigeKlammern{\klammern{Z(x)-M(x)}\mal\klammern{\overline{Z(y)-M(y)}}}
		\qquad\forall x,y\in T
	\end{align*}
	definiert, wobei
	$M(x):=\E\eckigeKlammern{Z(x)}$.
\end{erinnerungnr}

\begin{satz}\label{satz3.1.2}
	Eine komplexwertige (reellwertige) Funktion $K\colon T\times T\to C(\R)$ ist genau dann Kovarianz- oder Korrelationsfunktion eines komplexen (reellen) Feldes 2. Ordnung, wenn für beliebige $x_1,\ldots,x_n$ die Matrix $\klammern[\big]{K(x_i,x_j)}_{i,j=1}^n$ positiv semidefinit (positiv semidefinit und symmetrisch) ist.
\end{satz}

\begin{erinnerung}
	 Eine Matrix $A=(a_{i,j})_{i,j=1}^n\in\C^{n\times n}$ heißt \define{positiv semidefinit}
	 \index{positiv semidefinit}
	 \begin{align*}
	 	\defiff\forall n\in\N:\forall c_1,\ldots,c_n\in\C:\sum\limits_{i,j=1}^n a_{i,j}\mal c_i\mal\overline{c_j}\geq 0
	 \end{align*}
\end{erinnerung}

\begin{proof}
	\betone{Zeige "$\Longrightarrow$":}\\
	Sei $K$ die Kovarianzfunktion eines komplexen Feldes $Z$. Dann gilt:
	\begin{align*}
		\sum\limits_{i,j=1}^n K(x_i,x_j)\mal a_i\mal\overline{a_j}
		\overset{\Def}&{=}
		\sum\limits_{i=1}^n\sum\limits_{j=1}^n\E\eckigeKlammern{\klammern{Z(x_i)-M(x_i)}\mal\klammern{\overline{Z(x_j)-M(x_j)}}}\mal a_i\mal\overline{a_j}\\
		&=\E\eckigeKlammern{\klammern{\sum\limits_{i=1}^n a_i\mal \klammern{Z(x_i)-M(x_i)}}\mal\klammern{\overline{\sum\limits_{j=1}^n a_j\mal \klammern{Z(x_j)-M(x_j)}}}}\\
		&=\E\eckigeKlammern{\abs{\sum\limits_{j=1}^n\klammern{Z(x_j)-M(x_j)}\mal a_j}}\geq0
		\qquad\forall a_1,\ldots,a_n\in\C
	\end{align*}
	Hierbei geht $z\mal\overline{z}=\abs{z}^2~\forall z\in\C$ und
	\begin{align*}
		\sum\limits_{i,j} Z_i\mal\overline{Z_j}
		=\klammern{\sum\limits_i Z_i}\mal\klammern{\overline{\sum\limits_j Z_j}}
		=\abs{\sum\limits_j z_j}^2\qquad\forall z_j\in\C
	\end{align*}
	Analog für Korrelationsfunktion.
	Symmetrie für $\R$ ist klar.\nl
	\betone{Zeige "$\Longleftarrow$":}
	Folgt aus Satz \ref{satz3.1.4}.
\end{proof}

\begin{lemma}\label{lemma3.1.3}
	Sei $C=(c_{j,k})_{j,k=1}^n$ eine positiv semidefinite komplexe Matrix
	und $A=(a_{j,k})_{j,k=1}^n:=\Re(C)\in\R^{n\times n}$, $B=(b_{j,k})_{j,k=1}^n:=Im(C)\in\R^{n\times n}$.
	Dann sind die $(2\mal n)\times(2\mal n)$-reelle Blockmatrix
	\begin{align*}
		D:=\big(d_{j,k}\big)_{j,k=1}^{2\mal n}=\begin{bmatrix}
			A & -B\\
			B & A
		\end{bmatrix}
	\end{align*}
	auch positiv semidefinit (im komplexen Sinne).
\end{lemma}

\begin{erinnerung}[Transponieren von Blockmatrizen]
	\begin{align*}
		\begin{bmatrix}
			A & B\\
			C & D
		\end{bmatrix}^T
		=\begin{bmatrix}
			A^T & C^T\\
			B^T & D^T
		\end{bmatrix}
	\end{align*}
\end{erinnerung}

\begin{proof}
	Aus der positiven Semidefinitheit von $C$ folgt $c_{j,k}=\overline{c_{k,j}}$, woraus wiederum $A=A^T$ und $B^T=-B$, also insgesamt $D^T=D$ folgt (Symmetrie).
	Für alle $r_1,\ldots,r_{2\mal n}\in\R$ gilt (weil $C$ positiv semidefinit ist):
	\begin{align*}
		0
		&\leq\sum\limits_{j=1}^n\sum\limits_{k=1}^n c_{j,k}\mal\klammern{r_j-\ii\mal r_{n+j}}\mal\klammern{r_k+\ii\mal r_{n+k}}\\
		&=\underbrace{\sum\limits_{j=1}^n\sum\limits_{k=1}^n c_{j,k}\mal\klammern{r_j\mal r_k+r_{n+j}\mal r_{n+k}}}_{
			\in\R
		}
		-\ii\mal\underbrace{\sum\limits_{j=1}^n\sum\limits_{k=1}^n c_{j,k}\mal\klammern{r_{n+j}\mal r_k-r_j\mal r_{n+k}}}_{
			\in\ii\mal\R
		}\\
		\overset{\ast}&{=}
		\sum\limits_{j=1}^n \sum\limits_{k=1}^n a_{j,k}\mal\klammern{r_j\mal r_k+r_{n+j}\mal r_{m+k}}
		+\sum\limits_{j=1}^n\sum\limits_{k=1}^n b_{j,k}\mal\klammern{r_{n+j}\mal r_k-r_j\mal r_{n+k}}\\
		\overset{\Def~D}&{=}
		\sum\limits_{j=1}^{2\mal n} \sum\limits_{k=1}^{2\mal n}  d_{j,k}\mal r_j\mal r_k
	\end{align*}
	Zu $\ast$: Die erste Summe ist reell, die zweite rein imaginär wegen $c_ {j,k}=\overline{c_{k,j}}$.\\
	Folglich ist $D$ positiv semidefinit im reellen Sinne.
	Da $D$ auch symmetrisch ist, ist $D$ auch positiv semidefinit im komplexen Sinne.
\end{proof}

\begin{satz}\label{satz3.1.4}
	Sei $M\colon T\to\C$ beliebig und $K\colon T\times T\to\C$ so, dass für beliebige $x_1,\ldots,x_n\in T$ die Matrix
	\begin{align}\label{eq:satz3.1.4_1}\tag{1}
		\Big(K\big(x_i,x_j\big)\Big)_{i,j=1}^n
	\end{align}
	positiv semidefinit ist.
	Dann existiert ein Gauß-Feld auf $T$ mit
	\begin{align}
		\E\eckigeKlammern[\big]{Z(x)}&=M(x)
		\label{eq:satz3.1.4_2}\tag{2}\\
		\E\eckigeKlammern{Z(x)\mal\overline{Z(y)}}-M(x)\mal\overline{M(y)}&=K(x,y)
		\label{eq:satz3.1.4_3}\tag{3}\\
		\E\eckigeKlammern{Z(x)\mal Z(y)}&=M(x)\mal M(y)
		\label{eq:satz3.1.4_4}\tag{4}
	\end{align}
	für alle $x,y\in T$.
	Sind $M$ und $K$ reellwertig, so existiert ein reelles Gauß-Feld $Z$ so, dass \eqref{eq:satz3.1.4_2} und \eqref{eq:satz3.1.4_3} gelten.
\end{satz}

\begin{bemerkung}
	Wenn ein Feld $Z$ die Gleichungen \eqref{eq:satz3.1.4_2} und \eqref{eq:satz3.1.4_4} erfüllt, dann ist
	\begin{align*}
		\E\eckigeKlammern{\klammern[\big]{Z(x)-M(x)}^2}=0
	\end{align*}
	und folglich $Z(x)=M(x)$ fast sicher, wenn $Z$ reell.
\end{bemerkung}

\begin{erinnerung}
	$f$ ist die charakteristische Funktion eines $d$-dimensionalen Gauß-verteilten Zufallsvektors
	\begin{align*}
		\iff f(t)=\exp\klammern{\ii\mal\scaProd{m}{t}-\frac{1}{2}\mal\scaProd{C\mal t}{t}}\qquad\forall t\in\R^d
	\end{align*}
	Hierbei ist $m\in\R^d$ (Erwartungsvektor) beliebig und $C$ eine positiv semidefinite $d\times d$-Matrix (Kovarianzmatrix).
\end{erinnerung}

\begin{proof}
	\betone{Fall 1: $M$ und $K$ seien reellwertig.}\\
	Seien $x_1,\ldots,x_n\in T$.
	Dann existiert eine Gaußverteilung auf $\R^n$ mit Erwartungsvektor
	$\klammern[\big]{M(x_1),\ldots,M(x_n)}$ und Kovarianzmatrix \eqref{eq:satz3.1.4_1}.
	Diese Verteilungen erfüllen die Konsistenzbedingungen von Kolmogorov 
	%\ref{bem1.3.8Kolmo} 
	\ref{satz:1.3.6ExistenzsatzVonKolmo} mithilfe von Aufgabe \ref{aufg:6} (prüfen!).
	Folglich existiert ein reelles Gauß-Feld mit \eqref{eq:satz3.1.4_2} und \eqref{eq:satz3.1.4_3}.\nl
	\betone{Fall 2: $M$ und $K$ seien komplexwertig.}
	Setze
	\begin{align*}
		\tilde{T}&:=T\times\set{1,2}\\
		\tilde{M}&\colon\tilde{T}\to\R^2,\qquad
		\tilde{M}(x,1):=\Re(M(x)),\qquad
		\tilde{M}(x,2):=\Im(M(x))\\
		\hat{K}&\colon\tilde{T}\times\tilde{T}\to\R,~~
		\begin{array}{l}
			\tilde{K}\klammern[\big]{(x,1),(y,1)}:=
			\tilde{K}\klammern[\big]{(x,2),(y,2)}:=
			\frac{1}{2}\mal\Re\klammern[\big]{K(x,y)}\\
			\tilde{K}\klammern[\big]{(x,1),(y,2)}:=
			-\tilde{K}\klammern[\big]{(x,2),(y,1)}:=
			-\frac{1}{2}\mal\Im\klammern[\big]{K(x,y)}\\
		\end{array}~~\forall x,y\in T
	\end{align*}
	Aus Lemma \ref{lemma3.1.3} folgt, dass $\tilde{K}$ positiv semidefinit auf $\tilde{T}\times\tilde{T}$ ist.
	Nach dem ersten Fall im Beweis existiert ein reelles Feld $\tilde{Z}$ auf $\tilde{T}$ so, dass \eqref{eq:satz3.1.4_2} und \eqref{eq:satz3.1.4_3} für $\tilde{M}$, $\tilde{K}$, $\tilde{Z}$ erfüllt sind.
	Wir definieren
	\begin{align*}
		Z(x):=\tilde{Z}(x,1)+\ii\mal\tilde{Z}(x,2)\qquad\forall x\in T
	\end{align*}
	Dann ist $Z$ ein komplexes Gauß-Feld, da $\tilde{Z}$ ein Gauß-Feld ist.
	Eine kurze Rechnung zeigt, dass $Z$ die Gleichungen 
	\eqref{eq:satz3.1.4_2}, \eqref{eq:satz3.1.4_3} sowie \eqref{eq:satz3.1.4_4} erfüllt.
\end{proof}

Bei Anwendungen / Modellbildung ist es häufig notwendig, eine Korrelationsfunktion anzugeben, die zu den vorhandenen Daten passt.
Deshalb ist es wichtig, Methoden für die Konstruktion von positiv semidefiniten Kernen zu kennen.
(Ein \define{Kern} ist einfach eine Funktion von zwei Variablen).
\index{Kern}

\begin{aufgabenr}[3.1.5, \texorpdfstring{\hyperref[loes:19]{Lösung siehe Anhang}}{Lösung siehe Anhang}]\label{aufg:19}\enter
	Seien $K,K_1,K_2$ Kovarianzfunktionen auf $T\times T$.
	Die folgenden Funktionen sind Kovarianzfunktionen auf $T\times T$:
	\begin{enumerate}[label=(\roman*)]
		\item $\begin{aligned}
			p_1\mal K_1+p_2\mal K_2
		\end{aligned}$ für beliebige $p_1,p_2\geq0$
		\label{item:aufg19_i}
		\item $K_1\mal K_2$
		\label{item:aufg19_ii}
		\item punktweise Grenzwert von Kovarianzfunktionen auf $T\times T$.
		\label{item:aufg19_iii}
		\item $\begin{aligned}
			(t,s)\mapsto f(t-s)\qquad\forall (t,s)\in T\times T,~T:=\R^d
		\end{aligned}$\\1
		wobei $f$ eine charakteristische Funktion ist.
		Insbesondere sind
		\begin{align*}
			\cos\klammern{t-s},\qquad\exp\klammern{-\abs{t-s}^\alpha},\qquad
			\frac{1}{1+\abs{t-s}^\alpha}
		\end{align*}
		für $\alpha\in(0,2]$ $t,s\in\R$ Kovarianzfunktionen.
		\label{item:aufg19_iv}
		\item $\varphi(K)$ wenn $\abs{K}<\rho$ wobei $\rho>0$ und 
		\begin{align*}
			\varphi(z)=\sum\limits_{n=1}^\infty a_n\mal z^n\qquad\exists a_n\geq 0
		\end{align*}
		und die Reihe absolut konvergiert auf $\set{z\in C:\abs{z}<\rho}$.
		Insbesondere sind 
		\begin{align*}
			\exp(K)
			\qquad\und\qquad
			\frac{1}{d-K}
		\end{align*}
		für beliebige $d\geq \rho$ Kovarianzfunktionen.
		\label{item:aufg19_v}
	\end{enumerate}
\end{aufgabenr}

\setcounter{satz}{5}

\begin{lemma}\label{lemma3.1.6}
	Die Kerne
	\begin{align*}
		K_1(x,y)&:=\min\set{x,y} &&\forall x,y\in [0,\infty)\\
		K_2(x,y)&:=\frac{1}{2}\mal\klammern[\big]{\abs{x}+\abs{y}-\abs{x-y}} &&\forall x,y\in\R
	\end{align*}
	sind positiv semidefinit.
\end{lemma}

%\begin{proof}
	\begin{aufgabenr}[\texorpdfstring{\hyperref[loes:20]{Lösung siehe Anhang}}{Lösung siehe Anhang}]\label{aufg:20}\enter
		Der Beweis ist Aufgabe.
		\betone{Hinweis für $K_1$:}\\
		Seien $x_1,\ldots,x_n\in[0,\infty)$.
		Zu zeigen: $A=\klammern[\big]{\min(x_i,x_j)}_{i,j=1}^n$ ist positiv semidefinit.
		Wir dürfen annehmen, dass $x_1\leq x_2\leq\ldots\leq x_n$.
		Dann ist
		\begin{align*}
			\det\klammern[\big]{A(x_1,\ldots,x_n)}
			&=:D_n(x_1,\ldots,x_n)\\
			&=\begin{vmatrix}
				x_1 & x_1 & \ldots & x_1\\
				x_1 & x_2 & \ldots & x_2\\
				\vdots & \vdots & \ddots & \vdots\\
				x_1 & x_2 & \ldots & x_n
			\end{vmatrix}\\
			\overset{}&{=}?
		\end{align*}
		\betone{Hinweis für $K_2$:}\\
		Lässt sich auf $K_1$ zurückführen.
		Allgemein gilt für positiv semidefinite Matrizen $A,B$, dass auch die Matrix
		\begin{align*}
			\begin{bmatrix}
				A & 0\\
				0 & B
			\end{bmatrix}
		\end{align*}
		positiv semidefinit ist.
	\end{aufgabenr}
%\end{proof}

\begin{satz}\label{satz3.1.7}
	Auf $T=\R$ existiert ein stetiger  (d.h. die Pfade sind stetig) reeller Gauß-Prozess $X$ mit $\E[X]=0$ und 
	\begin{align}\label{eq:satz3.1.7_1}\tag{1}
		\E\eckigeKlammern[\big]{X(t)\mal X(s)}
		&=\frac{1}{2}\mal\klammern[\big]{\abs{t}+\abs{s}-\abs{t-s}}
		\qquad\forall s,t\in\R
	\end{align}
	Für $s,t\in[0,\infty)$ gilt speziell
	\begin{align}\label{eq:satz3.1.7_2}\tag{2}
		\E\eckigeKlammern[\big]{X(t)\mal X(s)}
		&=\min\set{s,t}\qquad\forall s,t\in[0,\infty)
	\end{align}
\end{satz}

\begin{proof}
	Die Existenz ohne stetige Pfade zu fordern folgt aus Lemma \ref{lemma3.1.6} und aus Satz \ref{satz3.1.4}.
	Für den Fall der stetigen Pfade:
	Ziel ist Anwendung des Satzes von Kolmogorov \ref{satz2.2.1Kolmo}.
	Da $X$ ein Gauß-Prozess ist, ist $X_t-X_s$ normalverteilt mit $\E\eckigeKlammern{X_t-X_s}=0$ und 
	\begin{align*}
		\Var(X_t-X_s)
		&=\E\eckigeKlammern{\klammern{X_t-X_s}^2}\\
		&=\E\eckigeKlammern{X_t^2-2\mal X_t\mal X_s+X_s^2}\\
		&=\abs{t}-\klammern[\big]{\abs{t}+\abs{s}-\abs{t-s}}+\abs{s}\\
		&=t-s
		\qquad\forall s\leq t\\
		\implies X_t-X_s&\sim\Nor(0,t-s)\\
		\implies
		X_t-X_s
		\overset{\d}&{=}
		\sqrt{t-s}\mal X_1\\
		\implies
		\E\eckigeKlammern{\klammern{X_t-X_s}^4}
		&=\klammern{t-s}^2\mal\E\eckigeKlammern{X_1^4}
	\end{align*}
	Jetzt ist der Satz von Kolmogorov \ref{satz2.2.1Kolmo} anwendbar mit $a=4$, $b=1$, $c=\E\eckigeKlammern{X_1^4}$.
	Es folgt aus dem Satz die Existenz einer stetigen Modifikation.
\end{proof}

\begin{bemerkungnr}\label{bem3.1.8}
	Ein Prozess mit den obigen Eigenschaften heißt \define{Wiener Prozess} oder \define{Brownsche Bewegung}.
	Oft werden die Einschränkungen auf $[ 0, \infty)$ oder $[ 0, a ]$ betrachtet. 
	Einige Autoren fordern nur die Stetigkeit von $\P$-fast allen Pfaden. 
	%Ohne Stetigkeitsforderung: schwacher Wiener Prozess.
	\index{Wiener Prozess}
	\index{Brownsche Bewegung|see{Wiener Prozess}}\nl
	%\index{schwacher Wiener Prozess}\nl
	Für $s\leq 0\leq t$ sind $X_s$ und $X_t$ unkorreliert.
	Da $X$ ein Gauß-Prozess ist, folgt aus der Unkorreliertheit die Unabhängigkeit.
\end{bemerkungnr}

\begin{bemerkungnr}\label{bem3.1.9}
	Es gibt auch andere Konstruktionsmöglichkeiten:
	\begin{enumerate}[label=(\alph*)]
		\item Sei $T>0$ beliebig und
		\begin{align*}
			X(t)&:=\sqrt{2\mal T}\mal\sum\limits_{n=1}^\infty\frac{\sin\klammern{\klammern{n+\frac{1}{2}}\mal\frac{\pi\mal t}{T}}}{\klammern{n+\frac{1}{2}}\mal\pi}\mal X_n^T\qquad\forall 0\leq t\leq T
		\end{align*}
		wobei $X_n^T\sim\Nor(0,1)$ unabhängig. Man kann zeigen:\\
		Diese Reihe konvergiert in $L^2$ 
		(Im Hilbertraum $H$: $\sum\limits_{n\in\N}e_n\mal c_n$ konvergiert in $H\gdw\sum\limits_{n\in\N}\abs{c_n}^2<\infty$)
		sogar fast sicher und $X$ besitzt die Kovarianzfunktion $\min\set{s,t}$.
		Alle Pfade sind stetig.
		\item Sei $C:=C\klammern{\intervall{0}{1}}$ der lineare Raum aller stetigen, reellwertigen Funktionen auf $\intervall{0}{1}$, versehen mit der Supremumsnorm
		\begin{align*}
			\norm{f}:=\sup\limits_{x\in\intervall{0}{1}}\abs[\big]{f(t)}\qquad\forall f\in C
		\end{align*}
		Dann ist $d(f,g):=\norm{f-g}$ eine Metrik auf $C$.
		Mit dieser Metrik ist $(C,d)$ vollständiger und separabler Banachraum.
		Mit $\B(C)$ bezeichnen wir (wie üblich) die Borel-$\sigma$-Algebra auf $C$.
		%Bei dieser Konstruktion zeigt man
		Man kann zeigen:
		Auf $\klammern[\big]{C,\B(C)}$ existiert ein Wahrscheinlichkeitsmaß $\mu$, das sogenannte \define{Wiener-Maß} mit der folgenden Eigenschaft:
		\index{Wiener-Maß}
		\begin{align*}
			W_t(\omega)&:=\omega(t)\qquad\forall t\in\intervall{0}{1},~\forall\omega\in C=:\Omega
		\end{align*}
		ist ein Wiener-Prozess auf $\intervall{0}{1}$.\nl
		\betone{Bemerkung:} Die Abbildungen $\omega\mapsto\omega(t)$ sind Gauß-sche Zufallsgrößen auf dem Wahrscheinlichkeitsraum $\klammern[\big]{X,\B(C),\mu}$.
		Die Stetigkeit der Pfade ist nach Konstruktion automatisch gegeben.\nl
		\textbf{Skizze der Konstruktion:}\\
		%Wir beschreiben kurz diese Konstruktion:
		Seien $X_1,X_2,\ldots$ unabhängige Zufallsgrößen auf einem Wahrscheinlichkeitsraum $\klammern{\Omega_0,\A_0,\P_0}$.
		Wir setzen $S_0:=0$, $S_k:=X_1+\ldots+X_k$, $k\in\N$ und
		\begin{align*}
			W_t^n(\omega)&:=\frac{1}{\sqrt{n}}\mal\klammern{S_{\floor{n\mal t}}(\omega)+\klammern[\big]{n\mal t-\floor{n\mal t}}\mal X_{\floor{n\mal t}+1}(\omega)}
			\forall n\in\N, t\in[0,1],\omega\in\Omega_0
		\end{align*}
	\end{enumerate}
\end{bemerkungnr}



