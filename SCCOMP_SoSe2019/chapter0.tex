% !TEX root = SCCOMP.tex
% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy
% of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or
% send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\chapter{Large Sparse Linear Systems}
\section{Model problems and discretization}%
\label{sec:Modelproblems and discretization}


\begin{equation}\label{eq:eq_1}\tag{1}
	\frac{\partial^2 u}{\partial x_1^2} + \frac{\partial^2 u}{\partial x_2^2} =: \laplace u = f(x) 
\end{equation}
with $\Omega \subset \R^2$ bounded, open domain and 
$ x =
\begin{pmatrix}
x_1 \\
x_2
\end{pmatrix}
\in \Omega$
\input{tikz/chapter0/example_omega.tex}
n outer normal on $\partial \Omega$
with boundary conditions
\[
\alpha u + \beta \frac{\partial u}{\partial n} = g \qquad \text{ on } \partial \Omega
.\] 

If \begin{itemize}
	\item $ \beta = 0$ and $\alpha=0$, we get a Dirichlet problem.
	\item  $\beta \neq 0$ and $ \alpha = 0$, we get a general Neumann problem.
	\item $\beta = 1$ and $\alpha = 0$, we have
		\begin{enumerate}
			\item Since $u = \text{const}$ solves \href{eq:eq_1}{(1)} 
				for $f=0 \text{ and } g = 0$, the solution to \href{eq:eq_1}{(1)} is unique up to a constant
			\item Integrating \href{eq:eq_1}{(1)} over $\Omega$ and Green's formula yield
				\[
				- \int_{\partial\Omega} \frac{\partial u}{\partial n} = - \int_{\Omega} \laplace u = \int_{\Omega} f
				.\] 
				This means, we get a compatibility condition
				\[
				\int_{\partial \Omega} g + \int_{\Omega}f = 0
				.\] 
		\end{enumerate}
\end{itemize} 

Another variant of \href{eq:eq_1}{(1)} is
\[
	Lu := \nabla(A\nabla u)
.\] 
where A is a positive definite matrix.

\begin{equation} \label{eq:eq_2}\tag{2}
LU = f \qquad \in \Omega \text{ + boundary condition}
\end{equation}

\section{Discretization with finite differences}%
\label{sec:Discretization with finite differences}

The basic idea is:

\begin{itemize}
	\item local approximation of partial derivatives
	\item derived by low order Taylor series
\end{itemize}

\begin{itemize}
	\item \underline{(1D-case):} 
		\[
			u'(x) \approx \frac{u(x+h)-u(x)}{h} = \delta^{+}u(x) \qquad \text{(forward difference)}
		.\] 
		For functions $u \in C^{4}$ in a neighbourhood of $x$, we get by Taylor's formula:
		\begin{equation} \label{eq:eq_3} \tag{$\ast$}
			u(x+h) = u(x) + h u'(x) + \frac{h^{2}}{2} u''(x) + \frac{h^{3}}{6}u'''(x) + \frac{h^{4}}{24}u''''(\xi_{+})	
		\end{equation}
		for some $\xi_{+} \in (x, x+h)$. Rearranging the equation gives
		\[
			u'(x) = \frac{u(x+h)-u(x)}{h}-\frac{h}{2}u''(x) + \O(h^{2})
		.\] 
		Now we plug this in in \href{eq:eq_4}{($\ast$)} and replace $h$ by $-h$ to get
		\begin{equation} \label{eq:eq_4} \tag{$\ast \ast$}
			u(x-h) = u(x) - hu'(x) + \frac{h^{2}}{2}u''(x)- \frac{h^{3}}{6} u'''(x) + \frac{h^{4}}{24}u''''(\xi _{-})
		\end{equation}
		For some appropriate $\xi _{-} \in (x-h, x)$.
		Adding up \href{eq:eq_3}{($\ast$)} and \href{eq:eq_4}{($\ast \ast)$} yields
		\[
			u''(x)= \frac{u(x+h) - 2u(x) + u(x-h)}{h^{2}} + \frac{h^{2}}{12}u''''(\xi )
		.\] for some $\xi  \in [\xi _{-}, \xi _{+}]$

		This is called the central difference approximation of the second order derivative.
		
		Let
		\[
			u'(x) \approx \frac{u(x)-u(x-h)}{h} = \delta^{-}u(x) \qquad \text{(backward difference)}
		.\] Then $u''(x) \approx \delta^{-}\delta^{+}u(x)$.

		For the elliptic operator $L:=\partial_{x} \Big(a(x)\partial_{x}\Big)$ we get a second order accurate formula by evaluating $a(x)$ inside the intervals $(x-h, x)$ and $(x, x+h)$
		\begin{align*}
			\partial_{x}(a(x) \partial_{x}u) &=
			\delta^{+}\Big(a(x- \frac{h}{2}) \delta^{-} u\Big) + \O(h^{2}) \\
											 &\approx \frac{a(x+\frac{h}{2})\Big(u(x+h)-u(x)\Big)-a(x-\frac{h}{2})\Big(u(x)-u(x-h)\Big)}{h^{2}}
		\end{align*}
		with $a(x \pm \frac{h}{2})$ either evaluated directly or by the average
		\[
			a(x \pm \frac{h}{2}) \approx \frac{1}{2}\Big(a(x \pm h) - a(x)\Big)
		.\] 
		
	\item \underline{(2D \& 3D cases):} 
		The laplacian is the sum of all second derivatives
		\[
			\laplace = \partial x_1^2 + \partial x_2^2 (+\partial x_3^2)
		.\] 
		With (possibly) different step width $h$ in each coordinate direction we get
		\begin{align*}
			\laplace u(x) &\approx \frac{u(x_1 + h_1, x_2) - 2u(x_1, x_2) + u(x_1 -h_1, x_2)}{h_1^2}\\
						  &+ \frac{u(x_1, x_2 + h_2) - 2u(x_1, x_2) + u(x_1, x_2 -h_2)}{h_2^2}
		\end{align*}
		but for $h_1 = h_2 = h$ we get
		\begin{align*}
			&\laplace u(x) \approx\\ 
			&\frac{1}{h^2}\left[u(x_1+ h, x_2) + u(x_1-h, x_2) + u(x_1, x_2 -h) + u(x_1, x_2 -h) -4u(x_1, x_2)\right].
		\end{align*}
		Denoting the forward/backward difference formulas
		in the direction i by $\delta_{i}^{+}$ and $\delta_{i}^{-}$ we can write
		\[
			\laplace u(x) \approx \sum_{i=1}^{2}{\delta_{i}^{+}\delta_{i}^{-}u(x)}=:\laplace_{h}^{(5)}u(x)
		.\] 
		The formula can be sketched as a stencil, the so called " 5-point stencil "
		\input{tikz/chapter0/five_point_stencil.tex}
		where the values in the nodes correspond to the coefficients in the formula.
		Other possible stencils are:
		\begin{itemize}
			\item rotated 5-point-stencil, $2^{\text{nd}}$ order accurate
				\input{tikz/chapter0/five_point_stencil_rot.tex}
			\item 9-point-stencil,  $2^{\text{nd}}$ order accurate and even $6^{\text{th}}$ order accurate for harmonic functions
				\input{tikz/chapter0/nine_point_stencil.tex}
		\end{itemize}
\end{itemize}

\subsection{Finite difference on a grid}%
\label{sec:Finite difference on a grid}
Let $\Omega =(0, X_{E}) \times (0,Y_{E})$ and subdivide each interval into $N_{x}+1 / N_{y} + 1$ subintervals.

\[
\left.
	\begin{array}{c}
	N_{x} = 1 \\
	N_{y} = 2
\end{array}
\right\} \qquad
h_{x} = \frac{x_{E}}{N_{x}+1}, \quad h_{y}= \frac{y_{E}}{N_{y}+1}
.\] 

\input{tikz/chapter0/fd_on_grid.tex}
Each node (vertex) in this grid is assigned an index tuple
\[
	(x,y) = (ih_{x}, jh_{y}) \stackeq{\wedge} (i,j)
.\] 
for $i \in \{0,1, \ldots , N_{x}+1\}, j \in  \{0,1, \ldots , N_{y}+1\}$

We denote the value at the node $(i,j)$ by
\[
	u(x,y)=u(ih_{x},jh_{y})=:u_{i,j}
.\] 
This results in the discrete Laplace operator $(h=h_{x}=h_{y})$
\[
	\laplace_{h}^{(5)}u_{i,j}=\frac{1}{2}(u_{i+1,j}+u_{i-1,j} +u_{i,j+1}+ u_{i,j-1} - 4u_{i,j})
.\]

\newpage
\subsection{Node ordering}%
\label{sec:Node ordering}
To form a linear system, the nodes $(i,j)$ have to be numbered consecutively, i.e. we have to use a map
\[
	l\colon \N^{d} \rightarrow \N
.\] 

Examples:

\begin{enumerate}[label=\alph{enumi})]
	\item  Lexicographical ordering
		\[
			l(i,j) = j \cdot (N_{x} + 2) + i 
			\quad\text{ or }\quad
			l(i,j) = i \cdot (N_{y} + 2) + j
		.\] 

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/lexi-ordering.tex}
			\end{center}
			\caption{Lexicographical ordering}
			\label{fig:lexiorder}
		\end{figure}
		
	\item Red-Black ordering (checkerboard ordering)

		\begin{enumerate}[label=\arabic{enumii})]
			\item neighbouring nodes get different color
			\item number each node lexicographically
		\end{enumerate}

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/red-black-ordering.tex}
			\end{center}
			\caption{Red-Black ordering}
			\label{fig:redblackorder}
		\end{figure}

		Question 1: How many colors do you need in 3D?

		Question 2: Does an analytic expression for $l(i,j)$ exist?
	\item Cache-aware ordering (Cluster nodes into connected groups)

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/cache-ordering.tex}
			\end{center}
			\caption{Cache-aware ordering, enumeration along the arrow lines}
			\label{fig:cacheorder}
		\end{figure}
		
		This ordering scheme utilizes the fact, that data which is "located in a neighbourhood in memory respectively" can be accessed much quicker and thus fastens the operations used on the matrices.

	\item Wave front orderings (diagonal ordering)

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/wave-ordering.tex}
			\end{center}
			\caption{Wave front ordering, enumeration along the arrow lines}
			\label{fig:waveorder}
		\end{figure}
		
\end{enumerate}

\subsection{Assembling}%
\label{sec:Assembling}

For the Poisson equation
\[
-\laplace u = f
.\] 
we can assemble a linear system $Au=f$ by applying the discrete operator $\laplace_{h}^{(5)}$ instead of $\laplace$ and by evaluating in the grid nodes
\[
	\begin{array}{ccl}
	A = (a_{rs}) 
	\quad&\text{ with }\quad 
	&a_{r(i,j),s(i',j')}= \frac{1}{h^{2}}\begin{cases}
		4 &\text{,if } r=s \\
		-1 &\text{,if } \abs{i-i'} = 1 \text{ and } \abs{j-j'} = 0 \\
		-1 &\text{,if } \abs{i-i'} = 0 \text{ and } \abs{j-j'} = 1 \\
		0 &\text{,otherwise}
	\end{cases} \\ \\
	f = (f_{r}) 
	\quad&\text{ with }\quad
	&f_{r(i,j)}=f(ih, jh)=f(x_{i}, y_{i})
	\end{array}
\] 
\[
	 A \stackeq{\wedge} -\laplace_{h}^{(5)}
.\] 

\subsection{Boundary conditions}%
\label{sec:Boundary condition}
For Dirichlet boundary condition the value $u$ at boundary nodes is fixed.

A node is boundary node if
\[
i \in  \{0, N_{x}+1\} \quad\text{ or }\quad j \in  \{0,N_{y}+1\}
.\] 

And so $u_{i,j} = g_{i,j}$ if $(i,j)$ is a boundary node.

The boundary condition can be realized by eliminating rows/columns in the matrix, i.e. let $r=l(i,j)$ a boundary index

\begin{align*}
	f &\leftarrow f-A_{\ast,r}\cdot g_{i,j} \\
	A_{r,\ast} &\leftarrow \delta_{r,s} \\
	A_{*,r} &\leftarrow \delta_{r,s} \\
	f_{r} &\leftarrow g_{i,j}
\end{align*}

\[
A\cdot \underline{u} = \underline{f}  
.\] 
\[
A = \begin{pmatrix}
	X & 
	\begin{matrix}
		0 \\
		\vdots
	\end{matrix} & X \\
	\begin{matrix}
		0 & \cdots 
	\end{matrix} & 1 &
	\begin{matrix}
		 \cdots & 0
	\end{matrix}\\
	X & \begin{matrix}
	\vdots \\
	0
	\end{matrix}
	  & X
	
	\end{pmatrix}
.\] 

\subsection{Structure of the matrix}%
\label{sec:Structure of the matrix}
(before eliminating the boundary conditions)
\begin{enumerate}[label=\alph{enumi})]
	\item Lexicographical ordering
		\[
		A= \frac{1}{h^{2}}
		\underbrace{
		\begin{bmatrix}
			[A_{0}] & [-I] &&& \\
			[-I] & [A_0] &&&\\
				 &&\ddots && \\
				 &&& [A_0] & [-I] \\
				 &&& [-I]& [A_0]
		\end{bmatrix}
		}_{N_{x}+2 \text{ blocks}}
		.\] 

		\[
		A_0 = \begin{bmatrix}
			4 & -1 &&& \\
			-1 & 4 & -1 && \\
			 & -1 & \ddots && \\
			 &&&\ddots & -1 \\
			 &&&-1 & 4
		\end{bmatrix}
		.\] 
	\item Red-Black ordering

		\[
			\begin{bmatrix}
				D_{r} & B \\
				B^{T} & D_{b}
			\end{bmatrix}
			\quad \text{with}\quad D_{r/b}=-\frac{1}{h^{2}}I_{r/b}
		.\] 
		B contains the values from the coupling of the nodes
\end{enumerate}

Variation of the PDE:
\[
\partial_{t}u- \laplace u=f
.\] 
Simple backward Euler scheme for $\partial_{t}$
\[
\frac{1}{\mathcal{T}}u^{m+1}- \laplace u^{m+1} = f -\frac{1}{\mathcal{T}}u^{m}
.\] 
with $u^{m} \equiv u(t^{m})$ with $0=t^{0}<t^{1}< \ldots  < t^{md}$ and $\mathcal{T}:=t^{m+1}-t^{m}$.

The corresponding FD discretization reads:

\[
	\left(\frac{1}{\mathcal{T}}I + A\right) u^{m+1} = f + \frac{1}{\mathcal{T}}u^{m}
.\] 

\subsection{Properties of the linear system}%
\label{sec:Properties of the linear system}

\begin{definition}
\label{thm:typeOfMatrices}
	A matrix $A \in  \R^{n \times n}$ is called
	\begin{itemize}
		\item \underline{Z-matrix}, if $a_{ij}\leq 0\quad \forall i\neq j$
		\item \underline{symmetric positive definite}, if $A=A^{T}$ and $A>0$, i.e. $u^{T}Au>0\quad\forall u \in \R^{n} \setminus 0$
		\item \underline{positive definite} , if $A+A^{T}>0$
		\item \underline{M-matrix}, if $A$ is Z-matrix and $\Re(\lambda) > 0 \quad\forall \lambda \in \sigma (A)$
		\item \underline{M$_{0}$-Matrix}, if it is pos. def. and Z-matrix (M$_{0}$-matrix is an M-matrix)
	\end{itemize}
\end{definition}

\begin{definition}
\label{thm:adjacenyGraph}
Let $A$ be a (sparse) matrix. The graph $G_{A}=(V,E)$ with $E \subset V \times V$ is called \underline{adjacency graph} of $A$ if 
\begin{itemize}[label=]
	\item $V$ represents the $n$ unknowns/rows/columns
	\item $V=\{1, \ldots, n\}$
	\item $E=\{(i,j) \in  V \times V : a_{ij}\neq 0\}$
\end{itemize}
(The edges represent the relation: equations $i$ involves unknown $j$)
\end{definition}

\begin{definition}
\label{thm:irreducible}
A matrix $A$ is called \underline{irreducible} if for $G_{A}=(V,E)$:
\[
	\forall i,j \in V ~:~ \exists \text{ sequence of edges } (e_0, e_1, \ldots , e_{n}) \subset E
\] 
such that
\[
	e_0=(i, k_0), e_1=(k_0,k_1),\ldots , e_{m}=(k_{m-1},j) \quad \text{with } k_{j} \in V
.\] 

(All vertices are connected by a sequence of edges)
\[
	\mathcal{IR}:= \{A \in  \R^{n \times  n} | A \text{ is irreducible}\}
.\] 
\end{definition}

\begin{definition}
\label{thm:WDDmatrices}
\begin{align*}
	WDD:= &\left\{ A \in \R^{n \times n}, \abs{a_{j,j}}  \geq \sum_{i\neq j}^{}{\abs{a_{i,j}} } \quad \forall j \right\}  \\
		 = &\left\{ A \in R^{n \times }, \abs{a_{i,i}} \geq \sum_{i\neq j}^{}{\abs{a_{i,j}} } \quad \forall i \right\} 
\end{align*}
are the weakly diagonal dominant matrices.
\[
DD:= \left\{ A \in WDD, \exists j : ">" \right\} 
\] 
are diagonal dominant matrices.
\[
SDD := \left\{ A \in WDD, \forall j : ">" \right\} 
\] 
are the strictly diagonal dominant matrices.
\[
IDD := \left\{ A \in DD, A \text{ is irreducible} \right\} 
\] 
are the irreducible diagonal dominant matrices.
\end{definition}

\begin{theorem}(Gershgorin)
\label{thm:gershgorin}
Any eigenvalue $\lambda \in \sigma (A)$ is located in one of the closed discs in the complex plane centered at $a_{i,i}$ and having the radius
\[
	\rho_{i} = \sum_{\substack{j=0 \\ j \neq i}}^{n}{\abs{a_{i,j}} }
.\] 
In other words : 
\[
	\forall \lambda \in \sigma (A) \exists i \text{ such that } \abs{\lambda - a_{i,i}}  \leq \sum_{\substack{j=0 \\ j \neq i}}^{n}{\abs{a_{i,j}} }
.\] 
\end{theorem}

\begin{proof}
\label{thm:gershgorinproof}
	Let $x$ be an eigenvector associated to eigenvalue $\lambda$ and let $m$ be the index of the component with largest modulus in $x$.

	Scale $x$, s.t.
	\[
	\abs{x_{m}}  = 1 \text{ and } \abs{x_{i}} \leq 1 \quad \forall i \neq m
	.\] 
	Since $x$ is an eigenvector to $A$, we have
	\[
		(\lambda - a_{n,m}) x_{m} = - \sum_{\substack{j=1 \\ j \neq m}}^{n}{\abs{a_{m,j}} x_{j}}
	.\] 
	Taking the absolute value of this, we get
	\[
		\abs{\lambda - a_{m,m}}  \leq \sum_{j\neq m}^{}{\abs{a_{m,j}} \abs{x_{j}} } \leq \sum_{j\neq m}^{}{\abs{a_{m,j}} } = \rho_{m}
	.\] 
\end{proof}
\input{tikz/chapter0/gershgorin_disks.tex}
\begin{theorem}
\label{thm:gershgorinboundary}
	Let $A$ be irreducible and assume that an eigenvalue $\lambda$ lies on the boundary of the union of all Gershgorin discs. Then $\lambda$ lies on the boundary of all Gershgorin discs.
\end{theorem}

\begin{proof}
\label{thm:gershgorinboundaryproof}
	Iterate proof of \href{thm:gershgorinproof}{the last proof} along the connecting edges of any pairs of nodes. Do this for all pairs and you get the result.
\end{proof}

\begin{corollary}
\label{thm:gershgorinboundarycorollary1}
	If $A$ is strictly diagonal dominant or $A$ is irreducible diagonal dominant, then $A$ is non-singular.
\end{corollary}

\begin{proof}
\label{thm:gershgorinboundarycorollary1proof}
	\begin{enumerate}[label=\alph{enumi})]
		\item Assume $A \in SDD$.

			Then the Gershgorin discs exclude the origin. This means $\lambda =0$ cannot be an eigenvalue of $A$.

		\item Assume $A \in IDD$.

			Then if it is singular, the zero eigenvalue lies on the boundary of the union of the Gershgorin discs. Together with \href{thm:gershgorinboundary}{Theorem 2} this implies that the eigenvalue should be located on the boundary of all discs.
			\[
				\implies \abs{a_{j,j}} = \sum_{i \neq j}^{}{\abs{a_{i,j}} } \qquad \forall j=0, \ldots , n
			.\] 
			$\lightning$, since $A$ is diagonal dominant.
	\end{enumerate}
\end{proof}

\begin{corollary}
\label{thm:gershgorinboundarycorollary2}
	Let $A \in R^{n \times  n}$. If 
	\[
		A \in WDD \text{ and } A = A^{T} \text{ and } \text{diag}(A) \geq 0
	,\] 
	then $A$ is pos. semidefinite. 
\end{corollary}

\begin{proof}
\label{thm:gershgorinboundarycorollary2proof}
\begin{align*}
& A \text{ symmetric} \\
	\implies & \text{ eigenvalues are real} \\
	\overset{(\ast)}{\implies} & \forall \lambda  \in \sigma (A) : \lambda  \geq 0
\end{align*}
[with $(\ast) = \text{diag(A)} \geq 0 + A \in WDD + $ \href{thm:gershgorin}{Theorem 1}] 
\end{proof}

\begin{summary}
\label{thm:summarymatrices}
The matrix $A = \laplace_{h}^{(5)}$ is 
\begin{itemize}
	\item symmetric $A = A^{T}$
	\item $A \in WDD$
	\item For Dirichlet boundary conditions we even have $A \in DD$
	\item irreducible
	\item $\text{diag}(A) \geq 0$
\end{itemize}
	$\implies A$ is positive definite and $A$ is $M_0$-matrix and thus $M$-matrix.
\end{summary}

\subsection{The non-zero structure of the matrix}%
\label{sec non-zero structure of the matrix}

A matrix $A \in \R^{n \times n}$ is called \underline{sparse matrix}, if the number of non-zero entries $(a_{i,j}\neq 0)$ is $\ll n^2$. Otherwise it is called a \underline{full matrix}. 

\begin{definition}
\label{thm:sparsetypes}
A (sparse) matrix is called a \underline{banded matrix}  with bandwidth $M$ if
\[
a_{i,j}\neq 0 \text{ only if } i-m_{l} \leq j \leq i + m_{u}
.\] 
with $m_{l},m_{u} \in \N_{>0}$ the lower and upper bandwidth and $M:=m_{l} + m_{u} + 1$.
\end{definition}

What is the bandwidth of $\laplace_{h}^{(5)}$? (using lexicographical ordering)

\begin{align*}
\begin{bmatrix}
	x & x &   &   & \\
	x & x & x &   & \\
	  & x & x & x & \\
	  &   & x & x & \\
	  &   &   &   & \ddots
\end{bmatrix}
\begin{bmatrix}
	x &   &   &   & \\
	  & \ddots &   &   & \\
	  &   & \ddots &   & \\
	  &   &   & \ddots & \\
	  &   &   &   & x
\end{bmatrix} \\
\underbrace{ 
\begin{bmatrix}
	x &   &   &   & \\
	  & \ddots &   &   & \\
	  &   & \ddots &   & \\
	  &   &   & \ddots & \\
	  &   &   &   & x
\end{bmatrix}}_{N_{x}+2}
\underbrace{ 
\begin{bmatrix}
	x & x &   &   & \\
	x & x & x &   & \\
	  & x & x & x & \\
	  &   & x & x & \\
	  &   &   &   & \ddots
\end{bmatrix}}_{A_0}
\end{align*}

The bandwidth of $A_0$ is 3.
We can deduce the other constants with this information:
\begin{itemize}
	\item $m_{l}=m_{u}=N_{x}+2 (\text{ or } N_{y}+2)$
	\item the boundary width of $A$ is $\O(n^{\frac{1}{2}})$ in 2D.
\end{itemize}

What is the number of non-zeros in $\laplace_{h}^{(5)} $?

\[
	nnz(A) \approx 5 \cdot n = 5(N_{x} +2)(N_{y} +2)
.\] 

\subsection{Finite Difference Refinement}%
\label{sec:Finite Difference Refinement}

Denote by $\Omega_{h}$ the mesh of grid points of width $h$, i.e. 
\[
	(x_{i}, y_{j}) = (ih, jh)
\] 
and by $\Omega_{H}$ the mesh of grid points with width $H$. Assume here $H=2h$.

\input{tikz/chapter0/grid_h_H.tex}

Given a discrete solution $u^{h}$ at $\Omega_{h}$, how to transfer the values to a coarser/finer mesh?

Answer: Use Interpolation!

The transfer from fine mesh $\Omega_{h}$ to coarse mesh $\Omega_{H}$ is called "\underline{Restriction}", denoted by $R_{h}^{H}$ and the transfer from coarse to fine mesh is called "Prolongation" denoted by $P_{H}^{h}$.
\[
R_{h}^{H}: \Omega_{h} \rightarrow \Omega_{H}, \quad
P_{H}^{h}: \Omega_{H} \rightarrow \Omega_{h}
.\] 

\begin{enumerate}[label=\Alph{enumi})]
	\item Prolongation:
		\begin{enumerate}[label=\underline{\arabic{enumi}D}]
			\item The simplest operator is defined by polynomial (linear) interpolation
		%TODO plot 1D interpolation Linie.
		\input{tikz/chapter0/grid_stencil_1D.tex}
		%\begin{figure}[ht!]
		%	\begin{center}
				%\includegraphics[width=0.5\textwidth]{pics/}
		%	\end{center}
		%	\caption{1D}
		%	\label{fig:prolongation}
		%\end{figure}
		\begin{align*}
			u_{2j}^{h} &= u_{j}^{H}  &\text{ for } j=0, \ldots, \frac{N+1}{2} \\
			u_{2j+1}^{h} &= \frac{1}{2}(u_{j}^{H}+u_{j+1}^{H})
		\end{align*}
		In matrix form, we obtain
		\[
		u^{h}= \frac{1}{2}\begin{bmatrix}
			1& & & & \\
			2& & & & \\
			1&1& & & \\
			 &2& & & \\
			 &1&1& & \\
			 & &2& & \\
			 & &1& & \\
			 & & &\ddots& \\
			 & & & &1 \\
			 & & & &2 \\
			 & & & &1
		\end{bmatrix}u^{H}
		.\] 
		Because of the specific coefficients, the interpolation is denoted in a stencil form by
		\[
			P_{H}^{h} \overset{\wedge}{=} \frac{1}{2}
			\left]
			\begin{matrix}
				1 & 2 & 1	
			\end{matrix}
			\right[
		.\] 

	\item The interpolation can be done in each coordinate direction.
		We get a tensor-product of the two 1D rules
		\begin{align*}
			u_{2i, 2j}^{h} &= u_{i,j}^{H} &i=0, \ldots, \frac{N_{x}+1}{2} \\
			u_{2i+1, 2j}^{h} &= \frac{1}{2}(u_{i,j}^{H}+u_{i+1,j}^{H}) &j=0, \ldots, \frac{N_{y}+1}{2} \\
			u_{2i,2j+1}^{h} &= \frac{1}{2}(u_{i,j}^{H}+u_{i,j+1}^{H}) \\
			u_{2i+1, 2j+1}^{h} &= \frac{1}{4}(u_{i,j}^{H}+ u_{i+1,j}^{H}+ u_{i,j+1}^{H}+ u_{i+1,j+1}^{H})
		\end{align*}
		In stencil form we get
		\[
			P_{H}^{h} \overset{\wedge}{=} \frac{1}{4}
			\left]
			\begin{matrix}
				1 & 2 & 1 \\
				2 & 4 & 2 \\
				1 & 2 & 1 
			\end{matrix}
			\right[
		.\] 
		\input{tikz/chapter0/grid_stencil_2D.tex}
		Note: if you interpret the 1D stencil as a row vector $p^{T}$, the 2D stencil is just the outer product 
		\[
		p\cdot p^{T}
		.\] 
		Note: higher order interpolation rules are possibly by incorporating more coarse grid rules.
		\end{enumerate}
\end{enumerate}

\subsection{Restriction}%
\label{sec:Restriction}

\begin{itemize}
	\item Simplest idea:

		"inject" the value on the fine grid node that correspond to a coarse grid node with an identity. In coefficient notation that is:
		\begin{align*}
			&\underline{\text{1D}}:& u_{i}^{H} &= u_{2i}^{h} \\
			&\underline{\text{2D}}:& u_{i,j}^{H} &= u_{2i, 2j}^{h}
		\end{align*}
		In stencil notation, that corresponds to
		\[
			R_{h}^{H} \stackeq{\wedge} \begin{bmatrix}
				1
			\end{bmatrix}
		.\] 
		This is called \underline{injection operator}. 

	\item Other idea: \underline{Full-weighting operator} 

		Use all neighbouring five grid values around a coarse grid node.

		Ansatz:

		\underline{1D}:
		\[
			\underbrace{\int_{\Omega_{x}}w^{h}}_{\substack{\text{use
			piecewise }\\\text{trapezoidal rule}}}
			\stackeq{!}
			\underbrace{\int_{\Omega_{x}}w^{H}}_{\substack{\text{use
			midpoint}\\\text{rule}}} \qquad \text{with }
			\Omega_{x} = [x-h, x+h]  
		.\] 
		From this, we get
		\[
			\frac{h}{2}(w^{h}(x-h) + w^{h}(x)) + \frac{h}{2}(w^{h}(x) + w^{h}(x+h)) \stackeq{!} 2hw^{H}(x) \\
		.\] 
		This implies
		\[
			w^{H}(x) = \frac{1}{4}(w^{h}(x-h)+2w^{h}(x) + w^{h}(x+h))
		.\] 
		%TODO Skizze linker & rechter Nachbar von Punkt
		\begin{align*}
			u_{j}^{H}= \frac{1}{4}(u_{2j-1}^{h}+2u_{2j}^{h}+ u_{2j+1}^{h})
		\end{align*}
		\[
			R_{h}^{H}\stackeq{\wedge}\frac{1}{4}\begin{bmatrix}
				1 & 2 & 1
			\end{bmatrix}
		.\] 
		\[
			R_{h}^{H}= \frac{1}{4}\begin{bmatrix}
				1 & 2 & 1 \\
				  &   & 1 & 2 & 1 \\
				  &   &   &   & 1 & 2 & 1 \\
				  &   &   &   &   &   &   & \ddots \\
			\end{bmatrix}
		.\] 
		% TODO hier etwas aufräumen und mit text füllen

		\underline{2D}:

		by tensor product
		\[
			R_{h}^{H}\stackeq{\wedge}=\frac{1}{16}\begin{bmatrix}
				1 & 2 & 1 \\
				2 & 4 & 2 \\
				1 & 2 & 1
			\end{bmatrix}
		.\] 
		\underline{Note}:

		The restriction operator using full-weighting is essentially the transpose of the linear prolongation operator with prefactor depending on the dimension d:
		\[
			P_{H}^{h} = 2^{d}R_{h}^{H}
		.\] 
\end{itemize}

\subsection{Relation between fine/coarse matrix $A^{h} / A^{H}$}%
\label{sec:Relation between fine/coarse matrix $A^{h} / A^{H}$}

\begin{itemize}
	\item The matrices can be assembled directly on the grid, i.e.
		\[
			A^{h} \stackeq{\wedge} \frac{1}{h^{2}}\begin{bmatrix}
			& -1 & \\
				-1 & 4 & -1 \\
				   & -1 & 
			\end{bmatrix}_{h},
			\qquad\qquad
			A^{H} \stackeq{\wedge} \frac{1}{H^{2}}\begin{bmatrix}
			& -1 & \\
				-1 & 4 & -1 \\
				& -1 & 
			\end{bmatrix}_{H}
		.\] 

	\item Another approach is the "Galerkin" relation:
		\[
		\tilde{A}^{H}:=R_{h}^{H}A^{h}P_{H}^{h}
		.\] 
\end{itemize}

\section{Finite-Element Discretization}%
\label{sec:Finite-Element Discretization}

For a Poisson equation
\[
- \laplace u = f \qquad \text{in }\Omega + \text{ BC }
\] 
go over to the weak formulation of the problem:

Find $u \in H_{0}^{1}(\Omega)$ such that
\[
	\int_{\Omega} \nabla u \cdot \nabla v \d x = \int_{\Omega} fv \d x \qquad \forall v \in H_{0}^{1}(\Omega )
\] 
or
\[
	\underbrace{ \int_{\Omega }\nabla u \cdot \nabla v \d x - \int_{\partial \Omega }gv \d s}_{a(u,v)} = \underbrace{ \int_{\Omega }fv \d x}_{F(v)} \qquad \forall v \in H^{1}(\Omega )
.\] 

\underline{FEM} :

Replace $V=H_{0}^{1}$ by finite dimensional subspace $V_{h}$ consisting of (low-degree) polynomials.
Let $\Omega $ be approximated/subdivided by $\Omega _{h}$ the union of $m$ geometric elements, e.g. triangles, hexagons, tetrahedrons, cubes, pyramids, $\ldots $
\[
\Omega \approx \Omega _{h} = \bigcup_{i=1}^{m}T_{i} \qquad \mathcal{T}_{h} := \left\{ T_{i} \right\} 
.\] 
Here $\mathcal{T}_{h}$ is called conforming, if facets of a element $T_{i}$ are also facets of other elements $T_{j}$.
The mesh size $h$ is defined by
\[
h = \max\limits_{T \in\mathcal{T}_{h}} \text{diam } T
.\] 
Where diam$(T):=\underset{x,y \in T }{\sup} |x-y|$.

An example of a finite-dimensional subspace is
\[
	V_{h}^{(0)} = \left\{ \phi \in C(\Omega _{h})\ |\ \phi|_{T} \in \P_{p} \text{ for } T \in \mathcal{T}_{h} \right\} \qquad (+ \text{ BC }, \phi|_{\partial \Omega _{h}}=0)
,\] 
where for $p=1$ we get linear Lagrange elements.
There are nodes $x_{j}$ in the triangulation (vertices, nodes on edges, $\ldots $) and a family
\[
	\left\{ \phi_{j} \right\} \subset V_{h} \qquad \text{with}\qquad \phi_{j}(x_{i}) = \delta_{i,j}
,\] 
which is uniquely defined by this relation.
So $\phi_{j}$ forms a basis of $V_{h}$.
Each function of $V_{h}$ can be expressed as
\[
	\phi(x) = \sum_{i=1}^{n}{\xi _{i}\phi_{i}(x)}
.\] 
As the result of this we get the approximation problem:

Find $u_{h} \in V_{h}^{(0)}$ such that

\begin{equation}\label{eq:discreteproblem}\tag{$\ast$}
	\underbrace{\int_{\Omega _{h}}\nabla u_{h}\cdot \nabla v_{h} \d x}_{a_{h}(u_{h},v_{h})} 
	=
	\underbrace{\int_{\Omega _{h}}f v_{h} \d x}_{F_{h}(v_{h})}  \qquad \forall v_{h} \in V_{h}^{(0)}
\end{equation}

Since $V_{h}$ is a linear space, testing with all the basis functions $\phi _{i}$ ends up in $n$ equations.

Let $u_{h}(x) = \sum_{i=1}^{n}{u_{i}\phi _{i}(x)}$.

Substitute into \href{eq:discreteproblem}{($\ast$)} and we obtain a linear system:

\[
\sum_{j=1}^{n}{a_{i,j}u_{j}=f_{i}}
,\] 
where
\begin{align*}
	a_{i,j}&= \int_{\Omega _{h}}\nabla \phi _{i}\nabla \phi _{j} \d x \\
f_{i}&=\int_{\Omega _{h}}f \phi _{i} \d x
\end{align*}
Using
\[
	A = (a_{i,j})_{i,j}, \qquad u=(u_{i})_{i}, \qquad f=(f_{i})_{i}
,\] 
we can denote the system by matrix notation as:
\[
A \cdot u = f
.\] 

Assemble A by local element contributions:
\[
	a_{h}(\phi _{i}, \phi _{j}) = \sum_{T \in \mathcal{T}_{h}}^{}{a_{T}(\phi _{i}, \phi _{j})}
,\] 
with
\[
	a_{T}(\phi _{i}, \phi _{j}) = \int_{T}\nabla \phi _{i}\cdot \nabla \phi _{j} \d x
.\]
The local element matrix $A_{T}$ consisting of contributions from $\phi _{i}$ local to $T$.
\[
	A = \sum_{T \in \mathcal{T}_{h}}^{}{A^{(T)}}= \sum_{T \in \mathcal{T}_{h}}^{}{P\cdot A_{T} \cdot R}
,\] 
with boolean matrices $P, R = P^{T}$.

\begin{enumerate}[label=\alph{enumi})]
	\item A is symmetric because $ \underbrace{a_{h}(\phi
		_{i}, \phi _{j})}_{a_{i,j}} =
		\underbrace{a_{h}(\phi _{j}, \phi _{i})}_{a_{j,i}}
		$
	\item A is positive definite
		\begin{proof}
		\label{thm:Aispositivedefinite}
			\[
					\underbrace{a_{h}(u,u)}_{u^{T}Au} = \int_{\Omega_{h} }\abs{\nabla u} ^2 \d x \geq 0 \qquad \forall u \in V_{h}
			.\] 
			If  $a(u,u)=0$ for a function $u$ in $V_{h}$, then $\nabla u=0$ almost everywhere in $\Omega _{h}$.

			Therefore $u$ is constant in every element $T$.

			Since $u \in C(\Omega _{h})$ and $u|_{\partial \Omega _{h}}=0$, $u \equiv 0$ has to hold in $\Omega _{h}$.
			\[
			\implies A \succ 0
			.\] 
		\end{proof}

	\item A is sparse
		\[
		\text{non-zeros per row } = \#\left\{ \text{functions with support in elements that share the Lagrange node} \right\} 
		.\] 

		\begin{figure}[H]
			\begin{center}
				\input{tikz/chapter0/square_with_inner_square.tex}
			\end{center}
			\caption{Example for the adjacency graph}
			\label{fig:adjacenygraph1}
		\end{figure}
		
		
		For linear Lagrange we have the following
		\[
		a_{i,j}\neq 0 \quad \text{if} \quad \exists T \in \mathcal{T}_{h}\colon x_{i}\in T \text{ and } x_{j} \in T
		.\] 

		For linear Lagrange in simplex triangulation, the grid corresponds to the adjacency graph.
		\begin{figure}[H]
			\begin{center}
				\input{tikz/chapter0/square_with_cross.tex}
			\end{center}
			\caption{Another example for the adjacency graph}
			\label{fig:adjacenygraph2}
		\end{figure}
		
\end{enumerate}

\subsection{A better definition of Finite-Element-spaces}
\label{sec:A better definition of Finite-Element-spaces}

$V_{h} \subset V$ finite-dimensional subspace / Finite-Element-space.

Let 
\begin{align*}
	V_{h} &= V_{h}(\mathcal{T}_{h}, \overline{\P}, V) \\
		  &= \Big\{  \phi \in V ~|~\phi |_{T} \in \P_{T}\quad\forall T \in \mathcal{T}_{h} \Big\}  ,
\end{align*}

with
\begin{itemize}
	\item $T$ is the space element in $\mathcal{T}_{h}$
	\item $\overline{T}$ is the reference element (barycentric element)
	\item $\overline{\phi }$ is a function in $\overline{\P}$, with $\overline{\phi }(\lambda ) = \overline{\phi }(\lambda (x)) =: \phi (x),\quad \phi  \in \P_{T},\quad (x \in T)$
\end{itemize}

Let $\left\{ \overline{\phi}_{1}, \ldots, \overline{\phi }_{m} \right\} $ be a basis of $\overline{\P}$ and let $\left\{ \phi _{1}, \ldots , \phi _{m} \right\}$ be a basis of $V_{h}$ such that for all $T \in \mathcal{T}_{h}$ and all $\phi _{j}$ that do not vanish on $T$, the following holds:
\[
	\phi _{j}|_{T}(x(\lambda )) = \overline{\phi }^{i}(\lambda ) \qquad \forall \lambda  \in \overline{T}
,\] 
with 
\begin{itemize}
	\item index mapping $ i= i_{T}(j)$, such that $i \in \left\{ 1, \ldots, m \right\} $ (global-to-local index mapping)
	\item inverse index mapping $j=j_{T}(i)$ (local-to-global index mapping)
\end{itemize}

\begin{align*}
	\phi _{j}|_{T}(x(\lambda )) &= \overline{\phi }^{i_{T}(j)}(\lambda ) \\
	\phi _{j_{T}(i)}(x(\lambda )) &= \overline{\phi }^{i}(\lambda )
\end{align*}

So the global solution $u_{h}\in V_{h}$ can be expressed in terms of its coefficient vector $u = (u_1, \ldots , u_{m})$
\[
	u_{h}(x)=\sum_{j=1}^{m}{u_{j}\phi _{j}(x)}
.\] 
or (on element $x \in T$) with local coefficient vector $(u_1^{T}, \ldots , u_{m}^{T}) = (u_{j_{T}(i)}, \ldots , u_{j_{T}(m)})$ with local basis functions $\overline{\phi }_{j}$
\[
	u_{h}(x) = \sum_{i=1}^{m}{u_{i}^{T}\overline{\phi }^{i}(\lambda (x))}
.\] 
Or correspondingly 
\[
	u_{h}(x(\lambda )) = \sum_{i=1}^{m}{u_{i}^{T}\overline{\phi }^{i}(\lambda )}= \sum_{i=1}^{m}{u_{j_{T}(i)}\overline{\phi }^{i}(\lambda )}
.\] 
Denote by $\Lambda(x)$ the jacobian
\[
	\Lambda(x) = \begin{pmatrix}
		- \nabla \lambda_0(x) - \\
		\vdots \\
		- \nabla \lambda_{d}(x) -
	\end{pmatrix}
.\] 
so that $\nabla \phi (x) = \Lambda^{T}(x)\nabla _{\lambda }\overline{\phi }(\lambda (x))$. We can express the bilinearform $a(\phi _{i}, \phi _{j})$ as 
\[
  a_{i,j} = a(\phi _{i}, \phi _{j}) = \sum_{T \in \mathcal{T}_{h}}^{}{a_{T}(\phi _{i}, \phi _{j}}) = \sum_{T \in \mathcal{T}}^{}{\int_{T}\nabla \phi _{i} \nabla \phi _{j} \d x}
.\] 
with
\[
	\int_{T}\nabla \phi _{i}(x)\nabla \phi _{j}(x) \d x = \int_{T}\nabla _{\lambda }\overline{\phi }^{i_{T}(i)}(\lambda (x)) \Lambda(x) \cdot \Lambda(x)^{T} \nabla _{\lambda }\overline{\phi }^{i_{T}(j)}(\lambda (x)) \d x
.\] 
Introduce the element stiffness matrix $A_{T} = (a_{i,j}^{T})$ as
\begin{align*}
	a_{i,j}^{T} &= \int_{T}\nabla _{\lambda }\overline{\phi }^{i}(\lambda (x)) \Lambda(x) \cdot \Lambda(x)^{T} \nabla _{\lambda }\overline{\phi }^{j}(\lambda (x)) \d x \\
				&= \int_{\overline{T}} \nabla _{\lambda }\overline{\phi }^{i}(\lambda ) \Lambda(x(\lambda )) \Lambda (x(\lambda ))^{T} \nabla _{\lambda} \overline{\phi }^{j}(\lambda ) \abs{\frac{\d x}{\d \lambda }} \d \lambda 
\end{align*}

Represent the local-to-global (and its inverse) map as matrices $P_{T}= (P_{r,s}^{T})$, $R_{T}=(R_{r,s}^{T})$ as
\begin{align*}
	P_{r,s}^{T}&= \delta_{r,j_{T}(s)} \\
	R_{r,s}^{T}&= \delta_{i_{T}(r),s}
\end{align*}
with $r = \left\{ 1, \ldots, n \right\} $ and $s = \left\{ 1, \ldots, m \right\} $
Thus the global matrix $A=(a_{i,j})$ is given by
\[
	A = \sum_{T \in \mathcal{T}}^{}{A^{(T)}} = \sum_{T \in \mathcal{T}}^{}{P_{T}A_{T}R_{T}}
.\] 

\begin{example}
\label{thm:examplefiniteelemtents}
\[
P_{T_{1}}= \begin{bmatrix}
	1& & \\
	 &1& \\
	 & &1\\
	0&0&0\\
	 &\vdots& \\
	0&0&0
\end{bmatrix},
\qquad
P_{T_{2}}= \begin{bmatrix}
	0&0&0\\
	0&0&0\\
	0&0&0\\
	1& & \\
	 &1& \\
	 & &1\\
	0&0&0\\
	 &\vdots& \\
	0&0&0
\end{bmatrix}
.\] 
\begin{align*}
	R_{T_1}&=\begin{bmatrix}
	1 & & & 0 &  & 0 \\
	 & 1 & &0 & \cdots & 0 \\
	 &&1 & 0 &  & 0
\end{bmatrix}
\qquad
(R_{T}=P_{T}^{T}) \\
		R_{T_2}&=\begin{bmatrix}
	0 &0 &0 &1 & & & 0 &  & 0 \\
	 0 &0 &0 && 1 & &0 & \cdots & 0 \\
	 0 &0 &0 &&&1 & 0 &  & 0
\end{bmatrix}
\end{align*}
\begin{figure}[ht!]
	\begin{center}
		\includegraphics[width=\textwidth]{pics/chapter0/weird_matrix_equation.png}
	\end{center}
	\caption{Example of the global matrix}
	\label{fig:globalmatrixequation}
\end{figure}
\end{example}

In the following $V_{h}$ space of linear finite elements, i.e. $\overline{\P}= \overline{\P}_{1}$ and $T \in\mathcal{T}_{h}$ is a triangle in 2D:

\begin{lemma}
\label{thm:stiffnessmatrixlemma}
	The non-zero entries of the stiffness matrix $A$, $a_{i,j}$, on a triangular grid are given by
	\[
		a_{i,j} = -\frac{1}{2}(\text{cot}(\alpha_{i,j}) + \text{cot}(\beta_{i,j})) \quad\text{ and }\quad a_{i,i} = -\sum_{x_{j}\in N(x_{i})}^{}{a_{j,i}}
	.\] 
	with $N(x_{i})=\left\{ x_{j} \in \Omega _{h} : \left[ x_{i},x_{j}\right] \text{ is an edge in the grid}   \right\} $ and $\alpha_{i,j}$, $\beta_{i,j}$ denote angles opposite to the edge $e=[x_{i}, x_{j}]$ in the triangles adjacent to $e$

	\begin{figure}[H]
		\begin{center}
			\input{tikz/chapter0/pentagon.tex}
		\end{center}
		\caption{Sketch of the involved part of the grid}
		\label{fig:pentagonrelations}
	\end{figure}
	

	\begin{itemize}
	\item Note: on boundary edges one side of the edge contributes to $a_{i,j}$
	\item Note: This form of stiffness matrix (Laplacian) is called \underline{Cotan-Laplacian} and can be derived by purely geometric arguments
	\item Note: The formula holds also for surface grids with $\text{dim}(\Omega _{h}) \neq \text{dim}(X)$
\end{itemize}

\end{lemma}

\begin{proof}
\label{thm:stiffnessmatrixlemmaproof}
\begin{enumerate}[label=\arabic{enumi})]
	\item The aspect ratio of a triangle can be expressed as the sum of $\cot$-s of the interior angles at its base.
		\[
		\frac{W}{h} = \cot \alpha + \cot \beta
		.\] 
		since
		\[
			\cot \alpha = \frac{W_{1}}{h},\quad \cot \beta = \frac{W_2}{h}
		.\] 
		\[
		\implies \frac{W_1}{h} + \frac{W_2}{h} = \frac{W}{h}
		.\] 
		\begin{figure}[H]
			\begin{center}
				\input{tikz/chapter0/triangle_explained.tex}
			\end{center}
			\caption{Sketch of the used properties}
			\label{fig:triangleexplained}
		\end{figure}
	\item Let $\vec{e}$ be the edge vector along the base of the triangle $T$. The gradient of the hat-function $\phi$ associated with the opposite vertex $v$ is given by
		\[
		\nabla \phi = \frac{1}{2\abs{T} }\vec{e}^{\bot}
		,\] 
		where $\vec{e}^{\bot}$ is the vector $\vec{e}$ rotated by a quarter turn in counter-clockwise direction and $\abs{T} $ is the area of $T$.
	\item Using everything we get 
		\[
			\int_{T}\nabla \phi \nabla \phi \d x = \frac{1}{2}(\cot \alpha + \cot \beta)
		.\] 
	\item For $\phi _{i}, \phi _{j}$ associated with vertices $x_{i}, x_{j}$ on the same element $T$, we have
		\[
		\int_{T}\nabla  \phi _{i} \nabla \phi _{j} \d x = - \frac{1}{2}\cot \theta
		,\] 
		with $\theta$ opposite to edge $[x_{i}, x_{j}]$
		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/small_triangle_explained.tex}
			\end{center}
			\caption{Sketch of the location of $\theta$}
			\label{fig:thetasketch}
		\end{figure}
		
\end{enumerate}
\end{proof}

\begin{remark}
\label{thm:stiffnessmatrixlemmaremark}
	We get the matrix vector product $A\cdot u = y$
	\begin{align*}
		y_{i} &= \sum_{j=1}^{n}{a_{i,j}u_{j}}\\
              &= \sum_{x_{j}\in N(x_{i})}^{}\underbrace{{\frac{1}{2}(\cot \alpha_{i,j}+ \cot \beta_{i,j})}}_{w_{i,j}}(u_{j}-u_{i}) \\
			  &= \sum_{x_{j}\in N(x_{i})}^{}{w_{i,j}(u_{j}- u_{i})}
	\end{align*}
\end{remark}

\begin{definition}
\label{thm:locallydelaunay}
	An edge $e$ of a triangulation $\mathcal{T}_{h}$ of $\Omega _{h}$ is \underline{locally Delaunay} if the sum of the angles opposite to $e$ in the adjacent triangles do not exceed $\pi $, i.e.
	\[
      e = [x_{i}, x_{j}] \qquad \alpha_{i,j} + \beta_{i,j}\overset{!}{\leq} \pi 
	.\] 
\end{definition}

\begin{definition}
\label{thm:delaunay}
	A triangulation is called \underline{Delaunay} if all interior edges are locally Delaunay.
\end{definition}

\begin{lemma}
\label{thm:delaunaylemma}
	For a Delaunay triangulation, the weights $w_{i,j}$ are non-negative and $A$ is a Z-matrix, i.e. $a_{i,j} \leq 0 \quad \forall i \neq j$
\end{lemma}

\begin{proof}
\label{thm:delaunaylemmaproof}
	\[
		\cot \alpha + \cot \beta = \frac{\sin(\alpha+\beta)}{\sin \alpha \sin \beta} \geq 0
	,\] 	
	if $\alpha + \beta \leq \pi $ and $\alpha,\beta \geq 0 $
\end{proof}

\underline{Summary}:
$A=(a(\phi _{i}, \phi _{j}))_{i,j}$ is (in a linear Lagrange triangulation setting)
\begin{itemize}
	\item symmetric
	\item sparse
	\item pos. definite
	\item Z-matrix if Delaunay
	\item $\abs{a_{i,i}} \geq \sum_{j}^{}{\abs{a_{i,j}} }$ + Delaunay for inner nodes
	\item irreducible
	\item $\text{diag}(A) \geq 0$
	\item number of non-zeros per row i : $\# \left\{ \text{ edges incident to node i } \right\} + 1$
\end{itemize}

\subsection{Finite-Element Refinement}
\label{sec:Finite-Element Refinement}

Consider two nested finite-element spaces.
\[
V_{H} \subset V_{h} \text{ on triangulations } \mathcal{T}_{H} \text{ and } \mathcal{T}_{h}
.\] 
respectively with 
\[
T = \bigcup_{j=1}^{m}t_{j} \text{ for all  } T \in \mathcal{T}_{H} \text{ with some } t_{j} \in \mathcal{T}_{h}
.\] 

\begin{exam}
\label{thm:refinementexamples}

\begin{itemize}
	\item bisection refinement
		% TODO : Bild 1
	\item red refinement
		% TODO : Bild 2
\end{itemize}
\end{exam}
We want to define a interpolation (prolongation) operator for the basis functions $\left\{ \phi _{i}^{H} \right\}_{i=1}^{K}$ of $V_{H}$ and $\left\{ \phi _{j}^{h} \right\} _{j=1}^{k}$ of $V_{h}$
\[
P_{H}^{h} \colon V_{H} \rightarrow V_{h}
.\] 
Since $V_{H} \subset V_{h}$ nested, the interpolation can be written as 
\[
P_{H}^{h}\phi _{j}^{H} = \sum_{i=1}^{k}{P_{i,j}\phi _{i}^{h}}
\] 
with $P = (P_{i,j})_{\substack{i=1, \ldots, k \\ j=1, \ldots, K}}$

Let $u^{H}=(u_{1}^{H}, \ldots , u_{K}^{H})$ and $u^{h}=(u_{1}^{h}, \ldots , u_{k}^{h})$ be the coefficient vectors of $u_{H} \in V_{H}$ and $u_{h} \in V_{h}$ respectively with respect to their basis $\left\{ \phi _{j}^{H} \right\} $ and $\left\{ \phi _{i}^{h} \right\} $.

Using the matrix $P$ from above, we conclude
\begin{align*}
	P_{H}^{h}u_{H} &= \sum_{j=1}^{K}{u_{i}^{H}P_{H}^{h}\phi _{i}^{H}} \\
				   &=\sum_{j=1}^{K}{u_{i}^{H}\sum_{i=1}^{k}{P_{i,j}\phi _{i}^{h}}} \\
				   &= \sum_{i=1}^{k}{(Pu^{H})_{i}\phi _{i}^{h}}
\end{align*}
and thus $u^{h} = Pu^{H}$ (where $u^{h}$ represents the coefficients on $\mathcal{T}_{h}$ respectively the coarse grid function $u_{H}$)

For model Lagrange FE, with Lagrange nodes $\left\{ x_{i} \right\} $, we have the relation
\[
	\phi _{i}(x_{j}) = \delta_{ij} \qquad \forall \phi _{i} \text{ in basis of } V_{h}
.\] 
Let $\left\{ x_{i}^{H} \right\} $ be the Lagrange nodes on $\mathcal{T}_{H}$ and $\left\{ x_{i}^{h} \right\} $ be the Lagrange nodes on $\mathcal{T}_{h}$.

The matrix $P$ is given by
\[
	P_{i,j} = \phi _{j}^{H}(x_{i}^{h}) \qquad 
	\begin{array}{l}
	i=1, \ldots, k \\
	j=1, \ldots, K
	\end{array}
.\] 
Galerkin relation between stiffness matrix $A_{h}$ and $A_{H}$.
\begin{align*}
	A_{H} &= (a_{H}(\phi _{r}^{H}, \phi _{s}^{H}))_{r,s}\\
	A_{h} &= (a_{h}(\phi _{r}^{h}, \phi _{s}^{h}))_{r,s}\\
\end{align*}
\begin{align*}
	a_{H}(\phi _{r}^{H}, \phi _{s}^{H}) &= a_{h}(P_{H}^{h}\phi _{r}^{H}, P_{H}^{h}\phi _{s}^{H}) \\
										&= a_{h}(\sum_{i=1}^{k}{P_{i,r}\phi _{i}^{h}}, \sum_{j=1}^{k}{P_{j,s}\phi _{j}^{h}}) \\
										&= \sum_{i,j=1}^{k}{P_{i,r}a_{h}(a_{i}^{h}, a_{j}^{h}) P_{j,s}}
\end{align*}
So
\[
	A_{H} = (P_{H}^{h})^{T}A_{h}P_{H}^{h}
\]
and thus we define the restriction operator as
\[
	R_{h}^{H} = (P_{H}^{h})^{T}
.\] 
